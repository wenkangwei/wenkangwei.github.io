<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>PySpark-Note-1 - Wenkang&#039;s Blog</title><meta description=""><meta property="og:type" content="article"><meta property="og:title" content="PySpark-Note-1"><meta property="og:url" content="https://github.com/wenkangwei/"><meta property="og:site_name" content="Wenkang&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2020-10-12T21:37:41.000Z"><meta property="article:modified_time" content="2020-10-12T21:58:10.786Z"><meta property="article:author" content="Wenkang Wei"><meta property="article:tag" content="PySpark"><meta property="article:tag" content="Data Analysis"><meta property="article:tag" content="KMean Clustering"><meta property="article:tag" content="Machine Learning"><meta property="twitter:card" content="summary"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://github.com/wenkangwei/wenkangwei.github.io%60/2020/10/12/PySpark-Note-1/"},"headline":"Wenkang's Blog","image":[],"datePublished":"2020-10-12T21:37:41.000Z","dateModified":"2020-10-12T21:58:10.786Z","author":{"@type":"Person","name":"Wenkang Wei"},"description":""}</script><link rel="canonical" href="https://github.com/wenkangwei/wenkangwei.github.io%60/2020/10/12/PySpark-Note-1/"><link rel="icon" href="/images/icon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/icon.png" alt="Wenkang&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-10-12T21:37:41.000Z" title="2020-10-12T21:37:41.000Z">2020-10-12</time><span class="level-item"><a class="link-muted" href="/categories/PySpark/">PySpark</a></span><span class="level-item">13 minutes read (About 1931 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">PySpark-Note-1</h1><div class="content"><img src=https://miro.medium.com/max/800/1*nPcdyVwgcuEZiEZiRqApug.jpeg>
<a id="more"></a>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This note is to introduce some useful functions in PySpark and also do some practice with them to analyze SF crime dataset. Then KMean Clustering model is applied to show how to use ML model in PySpark.</p>
<h2 id="List-of-Useful-Functions"><a href="#List-of-Useful-Functions" class="headerlink" title="List of Useful Functions"></a>List of Useful Functions</h2><ol>
<li><p>Create Spark Session</p>
<ul>
<li><p><strong>SparkSession</strong><br>  Create spark session, the main entry to create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables, and read parquet files. </p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark = SparkSession.builder \</span><br><span class="line">.master(<span class="string">"local"</span>) \</span><br><span class="line">.appName(<span class="string">"Word Count"</span>) \</span><br><span class="line">.config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">.getOrCreate()</span><br></pre></td></tr></table></figure>
<p>  Explanation:</p>
<ul>
<li>.master(‘local’): sets the Spark master URL to connect to. “local” mean run spark locally. Just like a local server</li>
<li>.appName(“Word Count”) : application name</li>
<li>.config(“spark.some.config.option”, “some-value”): configure some key-value pair in application</li>
<li>.getOrCreate():  Gets an existing SparkSession or, if there is no existing one, creates a new one</li>
</ul>
</li>
<li><p><strong>SQLContext</strong><br> <strong>As of Spark 2.0, this is replaced by SparkSession</strong>. However, this class is kept here for backward compatibility.<br>  A SQLContext can be used create DataFrame, register DataFrame as tables, execute SQL over tables, cache tables,and read parquet files.</p>
</li>
</ul>
</li>
<li><p><strong>Load data</strong><br> After we create a SparkSession, we can use the following code to read data from CSV or JSON file.<br> <strong>Returned Object:</strong> PySpark DataFrame object</p>
<ul>
<li>csv<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set delimiter = ";" between columns</span></span><br><span class="line"><span class="comment"># Skip header of file if header=True. </span></span><br><span class="line"><span class="comment"># Otherwise, load header as data record</span></span><br><span class="line">spark.read.options(header= <span class="literal">True</span>,delimiter=<span class="string">";"</span>) \</span><br><span class="line">.csv(<span class="string">"path-to-dataset/dataset.csv"</span>)</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">spark.read.options(header= <span class="literal">True</span>,delimiter=<span class="string">";"</span>) \</span><br><span class="line">.format(<span class="string">'csv'</span>).load(<span class="string">"path-to-dataset/dataset.csv"</span>)</span><br></pre></td></tr></table></figure></li>
<li>json<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark.read.json(<span class="string">"path-to-dataset/dataset.json"</span>)</span><br><span class="line"><span class="comment">#or</span></span><br><span class="line">spark.read.format(<span class="string">'json'</span>).load(<span class="string">"path-to-dataset/dataset.json"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Useful functions of pyspark.sql.DataFrame with SQL</strong></p>
</li>
</ol>
<ul>
<li><p><strong>Create DataFrame and SQL table</strong></p>
<ul>
<li><p><strong>df.createDataFrame(data, schema=None)</strong>:<br>  create  PySpark dataframe<br>  <strong>data</strong>: a list of tuples,each tuple contains the data of a row<br>  <strong>schema</strong>: a list of column names of dataframe</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder\</span><br><span class="line">.master(<span class="string">"local"</span>).appName(<span class="string">"Word Count"</span>)\</span><br><span class="line">.config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>).getOrCreate()</span><br><span class="line">l1 = [(<span class="string">'Alice'</span>, <span class="number">1</span>)]</span><br><span class="line">new_row1 = spark.createDataFrame(l1,[<span class="string">"name"</span>,<span class="string">"age"</span>])</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>df.createGlobalTempView(view_name)</strong><br>  Creates a <em>global</em> temporary <em>view</em> with this DataFrame.</p>
</li>
<li><p><strong>df.createOrReplaceTempView(view_name):</strong><br>  Creates or replaces a <em>local</em> temporary <em>view</em> with this DataFrame.</p>
</li>
<li><p><strong>df.registerDataFrameAsTable(table_name):</strong><br>  Registers the given DataFrame as a <em>temporary table</em> in the catalog.</p>
<br>
</li>
</ul>
</li>
<li><p><strong>Show Columns, Rows, Statistic description</strong></p>
<ul>
<li><p><strong>df.columns</strong>: a list of column names</p>
</li>
<li><p><strong>df.summary()</strong>: Computes specified <strong>statistics</strong> for numeric and string columns, with <em>count - mean - stddev - min - max</em>.</p>
</li>
<li><p><strong>df.describe()</strong>: Computes basic statistics for numeric and string columns. Similar to <em>summary()</em></p>
</li>
<li><p><strong>df.printSchema()</strong>: print Schema / decriptions of each column, like data type</p>
<br>
</li>
</ul>
</li>
<li><p><strong>Query and Selection</strong></p>
<ul>
<li><p><strong>df.head(10)</strong>: return the top 10 rows in Row type, <strong>not DataFrame</strong></p>
</li>
<li><p><strong>df.tail(10)</strong>:return the last 10 rows in Row type, <strong>not DataFrame</strong></p>
</li>
<li><p><strong>df.where(condition) or df.filter(condition)</strong> :  select the rows which satisfy the conditions. <strong>Return a DataFrame</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select ages that are &lt; 100 and City name = "SF"</span></span><br><span class="line"><span class="comment"># Using SQL expression in conditions</span></span><br><span class="line">df.where(<span class="string">"age &lt; 100 and city in ('SF') "</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Using Spark API</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col</span><br><span class="line">df.where(col(<span class="string">"age"</span>)&lt;<span class="number">100</span> &amp; col(<span class="string">'city'</span>).isin([<span class="string">"SF"</span>]))</span><br></pre></td></tr></table></figure></li>
<li><p><strong>df.column.isin([‘a’,’b’])</strong><br>Check if the value in a column is in the list or not</p>
</li>
<li><p><strong>df.column.between(lower_bound, upper_bound)</strong><br>check if the value is within a range or not</p>
</li>
<li><p><strong>df.select([“column-name”])</strong>:<br>select the columns based on a list of given column-names</p>
</li>
<li><p><strong>df.take(N)</strong>:<br>Return a list the top  N rows in Row() format</p>
</li>
<li><p><strong>df.collect()</strong>:<br>convert pyspark dataframe to a list of row in Row() format</p>
<br>
</li>
</ul>
</li>
<li><p><strong>Handle data</strong></p>
<ul>
<li><strong>df.withColumn(‘column_name’, col)</strong>:<br>append a column  to dataframe with name “column_name”</li>
</ul>
<p>  <strong>col</strong>: a Column expression for the new column. we can use UDF (user defined function) to it as well.</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.withColumn(<span class="string">"age"</span>, df.age+<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>df.withColumnRenamed(“old name”,”new name”)</strong>:<br>rename a column in the dataframe</p>
</li>
<li><p><strong>df.drop([“column-name”]),  df.dropna(subset =[“column-name”]))</strong>:<br>drop columns and drop the rows with NaN in selected columns</p>
</li>
<li><p><strong>df.dropDuplicates([“column-name-to-remove-duplicated-value”])</strong>:<br>drop duplicated rows in selected coumns</p>
</li>
<li><p><strong>df.fillna(), df.fill_duplicates()</strong>: fill na with given values</p>
</li>
<li><p><strong>df.spark.sql.Row(age=10, name=’A’)</strong>:<br>Return a row with elements: age=10, name=’A’</p>
</li>
<li><p><strong>df.orderBy([“column-name”], ascending=False), df.sortBy()</strong>:<br>orderBy is an alias of sortBy, they sort the dataframe along given column names</p>
</li>
<li><p><strong>df.groupby().agg() / df.groupby().count()</strong><br>Apply aggregation function, such as count()  to a group</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First select group based on column A, B.  Then count the amount of group "A"</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> F</span><br><span class="line">df.groupby([<span class="string">"A"</span>]).agg(F.count(df.A))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>Append New Rows</strong>        </p>
<ul>
<li><p><strong>df.union()</strong>:<br>Return a new DataFrame containing union of rows in this and another DataFrame, based on <strong>position</strong>.</p>
</li>
<li><p><strong>df.unionByName([“colunm-name”])</strong><br>The difference between this function and union() is that this function <strong>resolves columns by name</strong> (not by position)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">new_row =  spark.createDataFrame([(<span class="string">"A"</span>,<span class="number">1</span>)],[<span class="string">"name"</span>,<span class="string">"count"</span>])</span><br><span class="line">df = df.union()</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>SQL</strong></p>
<ul>
<li>df = SparkSession.sql(“select * from table”)</li>
</ul>
</li>
<li><p><strong>Display Data</strong></p>
<ul>
<li>df.show(n)</li>
</ul>
</li>
<li><p><strong>Data Types Convertion with Pandas</strong>  </p>
<ul>
<li><p><strong>df.toPandas()</strong><br>convert dataframe to pandas dataframe</p>
</li>
<li><p><strong>df.toDF()</strong><br>convert a list of Rows to PySpark dataframe</p>
</li>
<li><p><strong>Convert Pandas DataFrame to PySpark DataFrame using Schema</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line">mySchema = StructType([ StructField(<span class="string">"col name1"</span>, IntegerType(), <span class="literal">True</span>)\</span><br><span class="line">                    ,StructField(<span class="string">"col name2"</span>, StringType(), <span class="literal">True</span>)\</span><br><span class="line">                    ,StructField(<span class="string">"col name3"</span>, IntegerType(), <span class="literal">True</span>)])</span><br><span class="line">spark_df = spark.createDataFrame(df, mySchema)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ol start="4">
<li>Using Resilient distributed Dataset (RDD)<br> RDD represents an immutable, partitioned collection of elements that can be operated on in parallel.<br> Please refer to the  official website about RDD<br>

</li>
</ol>
<h2 id="Practice-with-Example-SF-Crime-data"><a href="#Practice-with-Example-SF-Crime-data" class="headerlink" title="Practice with Example: SF Crime data"></a>Practice with Example: SF Crime data</h2><ol start="0">
<li><p><strong>Requirements:</strong></p>
<ul>
<li>Find a platform for distributed computing, like databricks</li>
<li>Install PySpark</li>
</ul>
</li>
<li><p><strong>Download SF Crime Data for Demo</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"https://data.sfgov.org/api/views/tmnf-yvry/rows.csv?accessType=DOWNLOAD"</span>)</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"sf_crime.csv"</span>,<span class="string">"w"</span>) <span class="keyword">as</span> f</span><br><span class="line">    f.write(r.content)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>Load Data with PySpark</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> to_date, to_timestamp, hour</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> year, month, dayofmonth, date_format</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> from_unixtime, unix_timestamp</span><br><span class="line"></span><br><span class="line"><span class="comment"># create SparkSession entry to handle data</span></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"crime analysis"</span>) \</span><br><span class="line">    .config(<span class="string">"spark.some.config.option"</span>, <span class="string">"some-value"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"><span class="comment"># load csv data</span></span><br><span class="line">df_opt1 = spark.read.option(<span class="string">"header"</span>, <span class="string">"true"</span>).csv(data_path)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p><strong>Visualize Data</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a view called "sf_crime" to the dataframe, so that we can use SQL</span></span><br><span class="line"><span class="comment"># to query data later</span></span><br><span class="line">df_opt1.createOrReplaceTempView(<span class="string">'sf_crime'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  if using databricks, we can use display function to see the data</span></span><br><span class="line">display(df_opt1 )</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">df_opt1.show()</span><br><span class="line"><span class="comment"># or </span></span><br><span class="line"><span class="comment"># show the schema of dataframe</span></span><br><span class="line">df_opt1.printSchema()</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Clean Data</strong><br>Change the string data type to date type, integer type and other suitable data type</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># convert data type and replace data</span></span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">'Hour'</span>, hour(df_opt1[<span class="string">'Time'</span>]))</span><br><span class="line"><span class="comment"># convert string to date type using unix_timestamp</span></span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">"Date"</span>,  to_date( from_unixtime(unix_timestamp(df_opt1[<span class="string">'Date'</span>], <span class="string">'MM/dd/yyy'</span>))))</span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">"Year"</span>,  year(df_opt1.Date))</span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">"Month"</span>,  month(df_opt1.Date))</span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">"Day"</span>,  dayofmonth(df_opt1.Date))</span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">'HasCriminal'</span>, (df_opt1[<span class="string">"category"</span>]!=<span class="string">"NON-CRIMINAL"</span>))</span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">"X"</span>,  df_opt1[<span class="string">"X"</span>].cast(<span class="string">"double"</span>))</span><br><span class="line">df_opt1 = df_opt1.withColumn(<span class="string">"Y"</span>,  df_opt1[<span class="string">"Y"</span>].cast(<span class="string">"double"</span>))</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><strong>Query and Select data I’m interested in</strong><br>I want to analyze the count of crime of each category here, so there are two ways to do this.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display Count of cime using SQL</span></span><br><span class="line">crimeCategory = spark.sql(<span class="string">"SELECT  category, COUNT(*) AS crime_counts FROM sf_crime GROUP BY category ORDER BY crime_counts DESC"</span>)</span><br><span class="line">crimes_pd_df = crimeCategory.toPandas()</span><br><span class="line">display(crimeCategory)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display Count of crime of each category Using PySpark</span></span><br><span class="line">crime_category_df = df_opt1.groupby(<span class="string">'category'</span>).count().orderBy(<span class="string">'count'</span>,ascending=<span class="literal">False</span>)</span><br><span class="line">crime_category_df = crime_category_df.withColumnRenamed(<span class="string">'count'</span>, <span class="string">'crime_counts'</span>)</span><br><span class="line">crime_category_df = crime_category_df.toPandas()</span><br><span class="line">display(crime_category_df)</span><br></pre></td></tr></table></figure>

<p><strong>Result</strong></p>
<img src=/images/spark/count.png>

<h2 id="Advance-Topic-Machine-Learning-Model"><a href="#Advance-Topic-Machine-Learning-Model" class="headerlink" title="Advance Topic: Machine Learning Model"></a>Advance Topic: Machine Learning Model</h2><p>Using KMean Clustering to find the 5 centers in which crimes occur frequently</p>
<ol>
<li><strong>Select Position data X,Y and then Use Interquantile Range method to find outliers of position</strong><br>Since KMean Clustering is sensitive to the outlier as it uses mean method to find the center of clusters,  we need to remove outliers first. </li>
</ol>
<ul>
<li><strong>Quantile Based method to remove outlier</strong>:</li>
</ul>
<p><strong>The outlier is defined as the data point that drop outside the range [Q1-1.5<em>IQR ,  Q3+1.5</em>IQR]</strong>,<br>where Q1 and Q3 are  the first and third quantile of dataset and IQR = Q3-Q1 is the interquantile range.<br><br></p>
<ul>
<li><strong>API in PySpark to find quantile:</strong></li>
</ul>
<p><strong>df.approxQuantile(col, probabilities, relativeError)</strong>:<br><strong>col:</strong> column to find quantile<br><strong>probabilities:</strong> a list of quantile probabilities we want to find. Here I want to find Q1 =0.25 and  Q3=0.75<br><strong>return</strong>: the a list values that correspond to the quantile in probabilities list.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># select the positions where crimes occur</span></span><br><span class="line">crime_cluster_df = df_opt1.where(<span class="string">"hasCriminal =true"</span>).select([<span class="string">"Hour"</span>, <span class="string">"PdDistrict"</span>, <span class="string">"X"</span>,<span class="string">"Y"</span>, <span class="string">"DayOfWeek"</span>, <span class="string">"category"</span>,<span class="string">"Resolution"</span>,<span class="string">"hasCriminal"</span>])</span><br><span class="line"><span class="comment"># crime_cluster_df.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Find the Q1, Q 3 Quantile</span></span><br><span class="line">bounds = &#123;</span><br><span class="line">    c: dict(</span><br><span class="line">        zip([<span class="string">"q1"</span>, <span class="string">"q3"</span>], crime_cluster_df.approxQuantile(c, [<span class="number">0.25</span>, <span class="number">0.75</span>], <span class="number">0</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> crime_cluster_df.select([<span class="string">"X"</span>,<span class="string">"Y"</span>]).columns</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute lower bound and upper bound of normal data</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> bounds:</span><br><span class="line">    iqr = bounds[c][<span class="string">'q3'</span>] - bounds[c][<span class="string">'q1'</span>]</span><br><span class="line">    bounds[c][<span class="string">'lower'</span>] = bounds[c][<span class="string">'q1'</span>] - (iqr * <span class="number">1.5</span>)</span><br><span class="line">    bounds[c][<span class="string">'upper'</span>] = bounds[c][<span class="string">'q3'</span>] + (iqr * <span class="number">1.5</span>)</span><br></pre></td></tr></table></figure>
<br>

<ol start="2">
<li><p>Remove Outliers based on upper bound and lower bound of quantile</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> *</span><br><span class="line">crime_cluster_df = crime_cluster_df.select([<span class="string">"X"</span>,<span class="string">"Y"</span>])\</span><br><span class="line">.where(col(<span class="string">"X"</span>).between(bounds[<span class="string">'X'</span>][<span class="string">'lower'</span>], bounds[<span class="string">'X'</span>][<span class="string">'upper'</span>])) \</span><br><span class="line">.where(col(<span class="string">"Y"</span>).between(bounds[<span class="string">'Y'</span>][<span class="string">'lower'</span>], bounds[<span class="string">'Y'</span>][<span class="string">'upper'</span>]))</span><br></pre></td></tr></table></figure>
<br>
</li>
<li><p>Assemble columns into one feature column before training<br>In PySpark, we need to put all feature columns into one single feature column  before we train the model.</p>
</li>
</ol>
<p><strong>VectorAssembler</strong> provides a way to assemble those features into one column.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ensemble multiple columns into one single feature column for training KMean Clustering</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line">vecAssembler = VectorAssembler(inputCols=[<span class="string">"X"</span>, <span class="string">"Y"</span>], outputCol=<span class="string">"features"</span>)</span><br><span class="line">crime_cluster_df = vecAssembler.transform(crime_cluster_df.select([<span class="string">"X"</span>,<span class="string">"Y"</span>]))</span><br></pre></td></tr></table></figure>
<br>

<ol start="4">
<li>KMean Clustering to learn data<br>In Machine Learning of PySpark, we need to set the name of feature column to <strong>“features”</strong>, otherwise, set <code>featuresCol=&quot;column-name&quot;</code> to select which feature column to learn in dataframe</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training KMean clustering</span></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> BisectingKMeans</span><br><span class="line">K=<span class="number">5</span></span><br><span class="line">bkm = BisectingKMeans(k=K, minDivisibleClusterSize=<span class="number">1.0</span>)</span><br><span class="line">model = bkm.fit(crime_cluster_df)</span><br><span class="line"><span class="comment"># predict at one single point</span></span><br><span class="line"><span class="comment"># print(model.predict(crime_cluster_df.head().features))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># predict clusters</span></span><br><span class="line"><span class="comment"># Output the prediction to the column called "Prediction"</span></span><br><span class="line">model.setPredictionCol(<span class="string">"Prediction"</span>)</span><br><span class="line">transformed = model.transform(crime_cluster_df).select(<span class="string">"X"</span>,<span class="string">"Y"</span>, <span class="string">"Prediction"</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Result</strong></p>
<img src=/images/spark/cluster.png>

<br>

<img src=/images/spark/centers.png>

<br>

<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>This tutorial introduce:</p>
<ol>
<li>List of useful PySpark functions and their basic usage</li>
<li>Use SF Crime dataset as a demo to see how to use PySpark to manipulate data and visualize them</li>
<li>How to use machine learning model: KMean Clustering in PySpark to learn data. <strong>Note: the APIs of ML in PySpark are  different from sklearn. Need to Pay attention to the difference.</strong><br>

</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=read#pyspark.sql.DataFrameReader">SparkReader,Writer</a><br>[2] <a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.filter">PySpark,SQL_module</a><br>[3] <a href="https://spark.apache.org/docs/2.2.0/api/python/_modules/pyspark/ml/classification.html">PySpark,ML_module</a><br>[4] <a href="https://stackoverflow.com/questions/52633916/outlier-detection-in-pyspark">PySpark,outlier_detection</a><br>[5] <a href="https://miro.medium.com/max/800/1*nPcdyVwgcuEZiEZiRqApug.jpeg">logo</a></p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/PySpark/">PySpark</a><a class="link-muted mr-2" rel="tag" href="/tags/Data-Analysis/">Data Analysis</a><a class="link-muted mr-2" rel="tag" href="/tags/KMean-Clustering/">KMean Clustering</a><a class="link-muted mr-2" rel="tag" href="/tags/Machine-Learning/">Machine Learning</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://ppoffice.github.io/hexo-theme-icarus-categorites-Plugins/Share/" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/11/02/DL-ConvolutionNetwork/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">DeepLearning-1 ConvolutionNetwork</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/09/30/ML-Model-LR/"><span class="level-item">ML Model - Regression models</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "kvXCKmDNxnA2486N29e5cP7i-MdYXbMMI",
            appKey: "0Lv5b0SqotzkGHQvD64u4AKo",
            
            avatar: "mm",
            
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "en",
            
            highlight: true,
            
            
            
            
            
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://github.com/wenkangwei" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Data-Collection/"><span class="level-start"><span class="level-item">Data Collection</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Data-Structure/Sorting/"><span class="level-start"><span class="level-item">Sorting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/Ensemble-Method/"><span class="level-start"><span class="level-item">Ensemble Method</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/Ensemble-Method/Accuracy-Improvement/"><span class="level-start"><span class="level-item">Accuracy Improvement</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Parallel-Computing/"><span class="level-start"><span class="level-item">Parallel Computing</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/PySpark/"><span class="level-start"><span class="level-item">PySpark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Recommendation-System/"><span class="level-start"><span class="level-item">Recommendation System</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Report/"><span class="level-start"><span class="level-item">Report</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Searching/"><span class="level-start"><span class="level-item">Searching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Searching/Data-Strucure/"><span class="level-start"><span class="level-item">Data Strucure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Statistic/"><span class="level-start"><span class="level-item">Statistic</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Amdahl-s-Law/"><span class="tag">Amdahl&#039;s Law</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Backpropagation/"><span class="tag">Backpropagation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bagging/"><span class="tag">Bagging</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BeautifulSoup/"><span class="tag">BeautifulSoup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Tree/"><span class="tag">Binary Tree</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting/"><span class="tag">Boosting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting-Machine/"><span class="tag">Boosting Machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BuckSort/"><span class="tag">BuckSort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Collaborative-Filtering/"><span class="tag">Collaborative Filtering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Confusion-Metric/"><span class="tag">Confusion Metric</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Convolution-Neural-Network/"><span class="tag">Convolution Neural Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Validation/"><span class="tag">Cross Validation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/D3-js/"><span class="tag">D3.js</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Analysis/"><span class="tag">Data Analysis</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dropout/"><span class="tag">Dropout</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ensemble-Learning/"><span class="tag">Ensemble Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Holdout/"><span class="tag">Holdout</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hypothesis-Test/"><span class="tag">Hypothesis Test</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Independence-Test/"><span class="tag">Independence Test</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/K-Mean-Clustering/"><span class="tag">K-Mean Clustering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KMean-Clustering/"><span class="tag">KMean Clustering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LGBM/"><span class="tag">LGBM</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Evaluation/"><span class="tag">Model Evaluation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Selection/"><span class="tag">Model Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Natural-Language-Representations/"><span class="tag">Natural Language Representations</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nature-Language-Processing/"><span class="tag">Nature Language Processing</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Negative-Sampling/"><span class="tag">Negative Sampling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/P-value/"><span class="tag">P-value</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Parallel-Computing/"><span class="tag">Parallel Computing</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Parallel-Speedup/"><span class="tag">Parallel Speedup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PySpark/"><span class="tag">PySpark</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROC-curve/"><span class="tag">ROC curve</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommendation-System/"><span class="tag">Recommendation System</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regular-Expression/"><span class="tag">Regular Expression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sorting/"><span class="tag">Sorting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stacking/"><span class="tag">Stacking</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Traversal/"><span class="tag">Traversal</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-Learning/"><span class="tag">Unsupervised Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Variable-Selection/"><span class="tag">Variable Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web-Scrapping/"><span class="tag">Web Scrapping</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-and-Deep/"><span class="tag">Wide and Deep</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-and-Deep-Model/"><span class="tag">Wide and Deep Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-vector/"><span class="tag">Word vector</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/binary-search/"><span class="tag">binary search</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bubble-sort/"><span class="tag">bubble sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/commands/"><span class="tag">commands</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/insertion-sort/"><span class="tag">insertion sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/merge-sort/"><span class="tag">merge sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/non-parametric-learning/"><span class="tag">non-parametric learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quick-sort/"><span class="tag">quick sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/review/"><span class="tag">review</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-03-08T05:00:46.000Z">2021-03-08</time></p><p class="title is-6"><a class="link-muted" href="/2021/03/08/Cpp-review/">Cpp review 1</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Programming/">Programming</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-02-19T03:22:29.000Z">2021-02-18</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/18/Statistic-Hypothesis-Testing/">Statistic- 1 Hypothesis-Testing</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Statistic/">Statistic</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-12-16T00:48:52.000Z">2020-12-15</time></p><p class="title is-6"><a class="link-muted" href="/2020/12/15/Recommendation-System-1/">Recommendation-System-1- Collaborative Filtering and Content-based Filtering</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-12-08T05:18:39.000Z">2020-12-08</time></p><p class="title is-6"><a class="link-muted" href="/2020/12/08/report/">CPSC 6300 Final Report</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Report/">Report</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-12-01T20:13:14.000Z">2020-12-01</time></p><p class="title is-6"><a class="link-muted" href="/2020/12/01/kkboxmusicrecommendation-notebook-v4/">KKBox Music Recommendation System</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/avatar.jpg" alt="Wenkang Wei"></figure><p class="title is-size-4 is-block line-height-inherit">Wenkang Wei</p><p class="is-size-6 is-block">computer engineering| machine learning</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Clemson,SC</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">27</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">59</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wenkangwei" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wenkangwei"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/wenkang-wei-588811167"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a></div></div></div><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#Introduction"><span class="mr-2">1</span><span>Introduction</span></a></li><li><a class="is-flex" href="#List-of-Useful-Functions"><span class="mr-2">2</span><span>List of Useful Functions</span></a></li><li><a class="is-flex" href="#Practice-with-Example-SF-Crime-data"><span class="mr-2">3</span><span>Practice with Example: SF Crime data</span></a></li><li><a class="is-flex" href="#Advance-Topic-Machine-Learning-Model"><span class="mr-2">4</span><span>Advance Topic: Machine Learning Model</span></a></li><li><a class="is-flex" href="#Summary"><span class="mr-2">5</span><span>Summary</span></a></li><li><a class="is-flex" href="#Reference"><span class="mr-2">6</span><span>Reference</span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/icon.png" alt="Wenkang&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2021 Wenkang Wei</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://github.com/wenkangwei/wenkangwei.github.io`',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>