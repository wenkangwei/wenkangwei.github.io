<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GNN-2-MessagePassing - Wenkang&#039;s Blog</title><meta description=""><meta property="og:type" content="article"><meta property="og:title" content="GNN-2-MessagePassing"><meta property="og:url" content="https://github.com/wenkangwei/"><meta property="og:site_name" content="Wenkang&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2021-06-18T23:00:02.000Z"><meta property="article:modified_time" content="2021-06-18T23:43:20.175Z"><meta property="article:author" content="Wenkang Wei"><meta property="article:tag" content="GNN"><meta property="article:tag" content="Graph"><meta property="twitter:card" content="summary"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://github.com/wenkangwei/wenkangwei.github.io%60/2021/06/18/GNN-2-MessagePassing/"},"headline":"Wenkang's Blog","image":[],"datePublished":"2021-06-18T23:00:02.000Z","dateModified":"2021-06-18T23:43:20.175Z","author":{"@type":"Person","name":"Wenkang Wei"},"description":""}</script><link rel="canonical" href="https://github.com/wenkangwei/wenkangwei.github.io%60/2021/06/18/GNN-2-MessagePassing/"><link rel="icon" href="/images/icon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/icon.png" alt="Wenkang&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-06-18T23:00:02.000Z" title="2021-06-18T23:00:02.000Z">2021-06-18</time><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></span><span class="level-item">35 minutes read (About 5294 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">GNN-2-MessagePassing</h1><div class="content"><img src=https://panonit.com/sites/default/files/Message-passing-in-oop.png>

<a id="more"></a>


<h1 id="GNN-2-Message-Passing-消息传递神经网络"><a href="#GNN-2-Message-Passing-消息传递神经网络" class="headerlink" title="GNN-2-Message Passing 消息传递神经网络"></a>GNN-2-Message Passing 消息传递神经网络</h1><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>在图神经网络里面，在对数据和样本之间的关系进行建模得到图的edge， node之后，我们需要在图里面把每个节点的信息根据它的neighbor的信息进行更新，从而达到node的信息更新和节点特征(Node Representation)的特征表达。而这个把node节点信息相互传递从而更新节点表征的方法也叫Message Passing。<br>MessagePassing是一种聚合邻接节点信息来更新中心节点信息的范式，它将卷积算子推广到了不规则数据领域，实现了图与神经网络的连接。消息传递范式因为简单、强大的特性，于是被人们广泛地使用。遵循消息传递范式的图神经网络被称为消息传递图神经网络。</p>
<p>这一节里面我们讨论和实践 图神经网络一下几点:</p>
<ul>
<li>Message Passing 的原理</li>
<li>PyG (PyTorch Geometric)里面的MessagePassing类的理解和改写</li>
<li>通过MessagePassing, GCNConv 搭建Graph Convolution Neural network (GCN) 并通过实际的数据进行训练</li>
<li>对MessagePassing的基类函数如 aggregation， update， 的method进行理解和使用</li>
<li><strong>Jupyter Notebook source code</strong> 可以看这里: <a href="https://github.com/wenkangwei/Datawhale-Team-Learning/blob/main/GNN/Task-2-MessagePassing/GNN-Task-2-MessagePassing.ipynb">https://github.com/wenkangwei/Datawhale-Team-Learning/blob/main/GNN/Task-2-MessagePassing/GNN-Task-2-MessagePassing.ipynb</a></li>
</ul>
<h2 id="2-How-Message-Passing-works"><a href="#2-How-Message-Passing-works" class="headerlink" title="2.How Message Passing works"></a>2.How Message Passing works</h2><ul>
<li><strong>Message Passing的基本思路</strong></li>
</ul>
<p>以图片为例，如果我们的任务是node prediction去预测node A的特征值/node representation，那么图片里node A就是target node。然后 MessagePassing的过程如下</p>
<ol>
<li>图中黄色方框部分内容的是一次邻居节点信息传递到中心节点的过程：B节点的邻接节点（A,C）的信息经过变换后聚合到B节点，接着B节点信息与邻居节点聚合信息一起经过变换得到B节点的新的节点信息。同时，分别如红色和绿色方框部分所示，同样的过程，C、D节点的信息也被更新。实际上，同样的过程在所有节点上都进行了一遍，所有节点的信息都更新了一遍。 每个node的值是同时更新的</li>
<li>把步骤1 的“邻居节点信息传递到中心节点的过程”进行多次。如图中蓝色方框部分所示，A节点的邻接节点（B,C,D）的已经发生过一次更新的节点信息，经过变换、聚合、再变换产生了A节点第二次更新的节点信息。多次更新后的节点信息就作为节点表征。</li>
<li>一句话总结就是每次都把图里面的node的信息根据邻居节点进行更新，并多次把图的信息不断刷新得到Node representation。</li>
</ol>
<img src=https://raw.githubusercontent.com/wenkangwei/team-learning-nlp/master/GNN/Markdown%E7%89%88%E6%9C%AC/images/image-20210516110407207.png>


<ul>
<li><strong>Message Passing GNN 的泛式</strong></li>
</ul>
<p>MessagePassing图神经网络遵循上述的“聚合邻接节点信息来更新中心节点信息的过程”，来生成节点表征。<strong>Message Passing GNN的通用公式可以描述为</strong><br>$$<br>\mathbf{x}_ i^{(k)} = \gamma^{(k)} ( \mathbf{x}<em>i^{(k-1)}, \square</em>{j \in \mathcal{N}(i)} , \phi^{(k)}(\mathbf{x}_i^{(k-1)}, \mathbf{x}<em>j^{(k-1)},\mathbf{e}</em>{j,i}) ),<br>$$</p>
<p>根据<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html">官方文档</a> 以及<a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#creating-message-passing-networks">CREATING MESSAGE PASSING NETWORKS</a>, 我们定义</p>
<ul>
<li><p>$\mathbf{x}^{(k-1)}_i\in\mathbb{R}^F$表示神经网络的$(k-1)$层中节点$i$的节点表征</p>
</li>
<li><p>$\mathbf{e}_{j,i} \in \mathbb{R}^D$ 表示从节点$j$到节点$i$的边的属性信息。</p>
</li>
<li><p>$\square$表示<strong>可微分</strong>的、具有排列不变性（<strong>函数输出结果与输入参数的排列无关</strong>）的函数, 比如aggregation 函数。比如sum， mean, min等函数和输入的参数顺序无关的函数。</p>
</li>
<li><p>$\gamma$ : <strong>可微分可导</strong>的update 函数，比如MLPs（多层感知器）</p>
</li>
<li><p>$\phi$: <strong>可微分可导</strong>的message 函数，比如MLPs（多层感知器）和 linear Projection等</p>
</li>
<li><p><strong>Note:</strong></p>
<ol>
<li><p>神经网络的生成节点表征的操作称为节点嵌入（Node Embedding），节点表征也可以称为节点嵌入。<strong>这里考虑节点嵌入只代指神经网络生成节点表征的操作</strong>。</p>
</li>
<li><p>未经过训练的图神经网络生成的节点表征还不是好的节点表征，好的节点表征可用于衡量节点之间的相似性。通过监督学习对图神经网络做很好的训练，图神经网络才可以生成好的节点表征。我们将在<a href="5-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%8A%82%E7%82%B9%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0.md">第5节</a>介绍此部分内容。</p>
</li>
<li><p>节点表征与节点属性的区分：遵循被广泛使用的约定，此次组队学习我们也约定，节点属性<code>data.x</code>是节点的第0层(GNN输入层)节点表征，第$h$层的节点表征经过一次的节点间信息传递产生第$h+1$层的节点表征。不过，节点属性不单指<code>data.x</code>，广义上它就指节点的属性，如节点的度(in-degree, out-degree)等。</p>
</li>
</ol>
</li>
</ul>
<h2 id="3-MessagePassing-Class-in-PyTorch-Geometric"><a href="#3-MessagePassing-Class-in-PyTorch-Geometric" class="headerlink" title="3. MessagePassing Class in PyTorch Geometric"></a>3. MessagePassing Class in PyTorch Geometric</h2><p>Pytorch Geometric(PyG)提供了MessagePassing基类，它封装了“消息传递”的运行流程。通过继承MessagePassing基类，可以方便地构造消息传递图神经网络。构造一个最简单的消息传递图神经网络类，我们只需定义message()方法（ 𝜙(..) ）、update()方法（ 𝛾(..) ），以及使用的消息聚合方案（aggr=”add”、aggr=”mean”或aggr=”max”。<strong>MessagePassing Base Class中这里最重要的3个函数是：</strong></p>
<ul>
<li><code>MessagePassing.aggregate(...)</code>：用于处理聚集到节点的信息的函数</li>
<li><code>MessagePassing.message(...)</code>：用于搭建传送到 node i的节点消息，相对于𝜙(..)函数</li>
<li><code>MessagePassing.update(aggr_out, ...)</code>: 用于更新节点的信息，相对于𝛾(..)</li>
</ul>
<p><strong>以下是一些常用函数的解释:</strong></p>
<ul>
<li><p><code>MessagePassing(aggr=&quot;add&quot;, flow=&quot;source_to_target&quot;, node_dim=-2)</code>: </p>
<ul>
<li><code>aggr</code>: aggregation function聚合函数的选项, 可以用 (“add”, “mean” or “max”)</li>
<li><code>flow</code>: 信息传递方向 (either “source_to_target” or “target_to_source”)</li>
<li><code>node_dim</code>：定义沿着哪个维度传播，默认值为-2，也就是节点表征张量（data.x, Tensor）的哪一个维度是节点维度。节点表征张量x形状为[num_nodes, num_features]，其第0维度/columns（也是第-2维度）是节点维度(节点的个数)，其第1维度（也是第-1维度）是节点表征维度，所以我们可以设置node_dim=-2。</li>
</ul>
</li>
<li><p><code>MessagePassing.propagate(edge_index, size=None, **kwargs)</code>: </p>
<ul>
<li><code>edge_index</code>: 一个matrix存放每条edge 的索引信息(起始和终止的node的index)</li>
<li><code>size</code>: 基于非对称的邻接矩阵进行消息传递（当图为二部图时），需要传递参数size=(N, M)。如果size=None, 默认邻接矩阵是对称的</li>
<li><code>**kwargs</code>：图的其他特征</li>
</ul>
</li>
<li><p><code>MessagePassing.message(...)</code>：</p>
<ul>
<li>首先确定要给节点$i$传递消息的边的集合：<ul>
<li>如果<code>flow=&quot;source_to_target&quot;</code>，则是$(j,i) \in \mathcal{E}$的边的集合；</li>
<li>如果<code>flow=&quot;target_to_source&quot;</code>，则是$(i,j) \in \mathcal{E}$的边的集合。</li>
</ul>
</li>
<li>接着为各条边创建要传递给节点$i$的消息，即实现$\phi$函数。</li>
<li><code>MessagePassing.message(...)</code>方法可以接收传递给<code>MessagePassing.propagate(edge_index, size=None, **kwargs)</code>方法的所有参数，我们在<code>message()</code>方法的参数列表里定义要接收的参数，例如我们要接收<code>x,y,z</code>参数，则我们应定义<code>message(x,y,z)</code>方法。</li>
<li>传递给<code>propagate()</code>方法的参数，如果是节点的属性的话，可以被拆分成属于中心节点的部分和属于邻接节点的部分，只需在变量名后面加上<code>_i</code>或<code>_j</code>。例如，我们自己定义的<code>meassage</code>方法包含参数<code>x_i</code>，那么首先<code>propagate()</code>方法将节点表征拆分成中心节点表征和邻接节点表征，接着<code>propagate()</code>方法调用<code>message</code>方法并传递中心节点表征给参数<code>x_i</code>。而如果我们自己定义的<code>meassage</code>方法包含参数<code>x_j</code>，那么<code>propagate()</code>方法会传递邻接节点表征给参数<code>x_j</code>。</li>
<li>我们用$i$表示“消息传递”中的中心节点，用$j$表示“消息传递”中的邻接节点。</li>
</ul>
</li>
<li><p><code>MessagePassing.aggregate(...)</code>：</p>
<ul>
<li>将从源节点传递过来的消息聚合在目标节点上，一般可选的聚合方式有<code>sum</code>, <code>mean</code>和<code>max</code>。</li>
</ul>
</li>
<li><p><code>MessagePassing.message_and_aggregate(...)</code>：</p>
<ul>
<li>在一些场景里，邻接节点信息变换和邻接节点信息聚合这两项操作可以融合在一起，那么我们可以在此方法里定义这两项操作，从而让程序运行更加高效。</li>
</ul>
</li>
<li><p><code>MessagePassing.update(aggr_out, ...)</code>: </p>
<ul>
<li>为每个节点$i \in \mathcal{V}$更新节点表征，即实现$\gamma$函数。此方法以<code>aggregate</code>方法的输出为第一个参数，并接收所有传递给<code>propagate()</code>方法的参数。</li>
</ul>
</li>
</ul>
<h2 id="4-Coding-Practice"><a href="#4-Coding-Practice" class="headerlink" title="4. Coding Practice"></a>4. Coding Practice</h2><h3 id="4-1-基于-Message-Passing的泛式-框架-搭建Graph-Convolution-Network-GCN"><a href="#4-1-基于-Message-Passing的泛式-框架-搭建Graph-Convolution-Network-GCN" class="headerlink" title="4.1 基于 Message Passing的泛式(框架)搭建Graph Convolution Network (GCN)"></a>4.1 基于 Message Passing的泛式(框架)搭建Graph Convolution Network (GCN)</h3><p>根据PyG的官方文档，**<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv"><code>GCNConv</code></a>** 的公式是</p>
<p>$$<br>\mathbf{x}_ i^{(k)} = \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} ),<br>$$</p>
<p>其中，$\mathbf{x}_i$ 的节点的特征是由它的近邻的node的信息(包括node i自己)进行更新，所以计算时j是节点i的邻居(包括节点i本身)的子集里面的node。 邻接节点的表征$\mathbf{x}_j^{(k-1)}$首先通过与权重矩阵$\mathbf{\Theta}$相乘进行变换，然后按端点的度$\deg(i), \deg(j)$进行归一化处理，最后进行求和。这个公式可以分为以下几个步骤：</p>
<ol>
<li>向邻接矩阵添加自环边。</li>
<li>对节点表征做线性转换。</li>
<li>计算归一化系数。</li>
<li>归一化邻接节点的节点表征。</li>
<li>将相邻节点表征相加（”求和 “聚合）。</li>
</ol>
<p>步骤1-3通常是在消息传递发生之前计算的。步骤4-5可以使用<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing"><code>MessagePassing</code></a>基类轻松处理。该层的全部实现如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>)  <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        <span class="comment"># Adds a self-loop (i,i)∈E to every node i∈V in the graph given by edge_index.</span></span><br><span class="line">        <span class="comment"># In case the graph is weighted, self-loops will be added with edge weights denoted by fill_value.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization: 1/sqrt(degree(i)) * 1/sqrt(degree(j))</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == float(<span class="string">'inf'</span>)] = <span class="number">0</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, norm)</span>:</span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## download data to current directory</span></span><br><span class="line"><span class="comment">#! wget https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'./dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># GCNConv: </span></span><br><span class="line"><span class="comment">#in_channels: dimension of input vector of linear layer</span></span><br><span class="line"><span class="comment"># out_channels: dimension of output vector of linear layer</span></span><br><span class="line"><span class="comment">#Note: the linear transform is performed before message passing to reduce the dimension of node representation</span></span><br><span class="line"><span class="comment"># After message passing, the amount of nodes doesn't change</span></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data.x: a matrix with each row representing the data in a node</span></span><br><span class="line"><span class="comment"># data.edge_index: matrix with shape [2, number of edges], each column representing edge from node to another node, value=index of node</span></span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line">print(h_nodes.shape)</span><br></pre></td></tr></table></figure>

<pre><code>torch.Size([2708, 64])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.x.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([2708, 1433])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="4-2-Overwrite-methods-messsage-aggregate-update"><a href="#4-2-Overwrite-methods-messsage-aggregate-update" class="headerlink" title="4.2 Overwrite methods: messsage, aggregate, update"></a>4.2 Overwrite methods: messsage, aggregate, update</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        print(<span class="string">"Before self-loop:"</span>,edge_index.shape)</span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line">        print(<span class="string">"After self-loop:"</span>,edge_index.shape)</span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="comment"># Convert edge index to a sparse adjacency matrix representation, with row = from nodes, col = to nodes, value = 0 or 1 indicating if</span></span><br><span class="line">        <span class="comment"># two nodes are adjacent.</span></span><br><span class="line">        adjmat = SparseTensor(row=edge_index[<span class="number">0</span>], col=edge_index[<span class="number">1</span>], value=torch.ones(edge_index.shape[<span class="number">1</span>]))</span><br><span class="line">        <span class="comment">#print("Adjacency matrix:",adjmat)</span></span><br><span class="line">        <span class="comment"># 此处传的不再是edge_index，而是SparseTensor类型的Adjancency Matrix</span></span><br><span class="line">        <span class="comment"># 当使用SparseTensor 时， propagate 会调用message_and_aggregate 函数</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(adjmat, x=x, norm=norm, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, norm, deg_i)</span>:</span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j * deg_i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">"`aggregate` is called"</span>)</span><br><span class="line">        <span class="keyword">return</span> super().aggregate(inputs, index, ptr=ptr, dim_size=dim_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message_and_aggregate</span><span class="params">(self, adj_t, x, norm)</span>:</span></span><br><span class="line">        print(<span class="string">'`message_and_aggregate` is called'</span>)</span><br><span class="line">        <span class="comment"># 没有实现真实的消息传递与消息聚合的操作</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, inputs, deg)</span>:</span></span><br><span class="line">        print(deg)</span><br><span class="line">        <span class="keyword">return</span> inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line"><span class="comment"># print(h_nodes.shape)</span></span><br></pre></td></tr></table></figure>

<pre><code>Before self-loop: torch.Size([2, 10556])
After self-loop: torch.Size([2, 13264])
Adjacency matrix: SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),
             col=tensor([   0,  633, 1862,  ..., 1473, 2706, 2707]),
             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
             size=(2708, 2708), nnz=13264, density=0.18%)
`message_and_aggregate` is called
tensor([[4.],
        [4.],
        [6.],
        ...,
        [2.],
        [5.],
        [5.]])
</code></pre>
<h2 id="5-Assignment"><a href="#5-Assignment" class="headerlink" title="5. Assignment"></a>5. Assignment</h2><ol>
<li>请总结<code>MessagePassing</code>基类的运行流程。</li>
<li>请复现一个一层的图神经网络的构造，总结通过继承<code>MessagePassing</code>基类来构造自己的图神经网络类的规范。</li>
</ol>
<h3 id="5-1-Message-Passing-机制总结"><a href="#5-1-Message-Passing-机制总结" class="headerlink" title="5.1 Message Passing 机制总结"></a>5.1 <strong>Message Passing 机制总结</strong></h3><p>Message Passing 根据上面讨论的的框架公式，在设计Message Passing 的流程可以归纳为以下几点:</p>
<ol>
<li>定义和选取 message 函数，𝜙(..)，并根据图的节点信息的输入($x_i^{k-1}, x_j^{k-1}, e_{i,j}$) 对输入进行变换(可导的，比如线性投映进行降维或乘上系数之类的)</li>
<li>定义和选取 aggregation 函数 $\square(..)$, 对转换后的信息进行邻居节点的信息聚合处理， 常用的有sum, mean, max之类的</li>
<li>定义和选取update()函数（ 𝛾(..) ），把原本的节点信息$x_i^{k-1}$ 和 聚合后的邻居节点信息($\square(..)$ 函数的输出)的信息进行整合，更新当前的节点信息得到$x_j^{k}$。</li>
</ol>
<p>用GCN的公式举个栗子，就是 </p>
<p>$$<br>\mathbf{x}_ i^{(k)} = \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} ),<br>$$</p>
<ul>
<li><p>GCN里面的 $\frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} )$ 的操作，里面的$\mathbf{\Theta}$ 线性投映和用degree做normalization相对于是 𝜙(..)函数的message的搭建</p>
</li>
<li><p>而 $\sum_{j \in \mathcal{N}(i) \cup { i }}$ 这一步相对于把邻居节点(包括节点自己)的信息进行聚合, 相对于aggregation 函数 $\square(..)$</p>
</li>
<li><p>GCN这里因为在做了aggregation后没有用到 $x_i^{k-1}$信息，所以update()函数, 𝛾($x_i^{k-1}, \square(..)$) 可以看成直接输出(或者是$\square()$信息聚合后乘上1就输出)。𝛾(..)其实也可以替换为其他可导的的非线性函数比如 logistics， relu之类的。</p>
</li>
<li><p>至于MessagePassing 的Base Class里面的message_and_aggregate()可以看成是 $\square(\phi(x_i^{k-1}, x_j^{k-1}, e_{i,j}))$</p>
</li>
<li><p>MessagePassing 的Base Class里面的propagate()函数可以看成是对 $\gamma(x_i^{k-1}, \square(\phi(…)))$ 更新函数的封装。 这一点可以看看官方文档的<a href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.propagate">源码</a></p>
</li>
</ul>
<h3 id="5-2-用MessagePassing-这个BaseClass去实现一个-我自定义的GCN-layer"><a href="#5-2-用MessagePassing-这个BaseClass去实现一个-我自定义的GCN-layer" class="headerlink" title="5.2 用MessagePassing 这个BaseClass去实现一个 我自定义的GCN layer"></a>5.2 <strong>用MessagePassing 这个BaseClass去实现一个 我自定义的GCN layer</strong></h3><p>这里我自定义的GCN layer公式如下：<br>$$<br>\mathbf{x}_ i^{(k)} = \sigma(\frac{1}{|\mathcal{N}(i)|+1} \times \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} ) ) +  \mathbf{\Theta}  \cdot \mathbf{x}_i^{(k-1)} ,<br>$$</p>
<p>这里一些函数定义如下：</p>
<ul>
<li>$\phi(..)$: message函数和之前的GCN一样都是linear projection之后用degree进行normalization</li>
<li>$\square(..)$ : aggregate 函数 用来mean</li>
<li>$\gamma(..)$: update 函数是先用了ReLu activation函数 $\sigma(.)$, 再加上shortcut把之前投映之后的输入加上来，引入resnet的结构</li>
<li>这里只用了 message_and_aggregate 函数，所以没有实现message， aggregate的单独的函数</li>
<li>propagate 函数是直接从官方文档copy过来，方便理解GNN的propagate的流程的。 从中可以看到，如果输入到propagate的tensor是SparseTensor, 那么会直接调用message_and_aggregate函数，而不是单独调用两个函数，所以只要实现这个合并的函数就行了</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor, matmul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'mean'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(self, edge_index, size=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># I just copy the source copy from PyG website</span></span><br><span class="line">        <span class="string">r"""The initial call to start propagating messages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor` that defines the underlying</span></span><br><span class="line"><span class="string">                graph connectivity/message passing flow.</span></span><br><span class="line"><span class="string">                :obj:`edge_index` holds the indices of a general (sparse)</span></span><br><span class="line"><span class="string">                assignment matrix of shape :obj:`[N, M]`.</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its</span></span><br><span class="line"><span class="string">                shape must be defined as :obj:`[2, num_messages]`, where</span></span><br><span class="line"><span class="string">                messages from nodes in :obj:`edge_index[0]` are sent to</span></span><br><span class="line"><span class="string">                nodes in :obj:`edge_index[1]`</span></span><br><span class="line"><span class="string">                (in case :obj:`flow="source_to_target"`).</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`, its sparse indices</span></span><br><span class="line"><span class="string">                :obj:`(row, col)` should relate to :obj:`row = edge_index[1]`</span></span><br><span class="line"><span class="string">                and :obj:`col = edge_index[0]`.</span></span><br><span class="line"><span class="string">                The major difference between both formats is that we need to</span></span><br><span class="line"><span class="string">                input the *transposed* sparse adjacency matrix into</span></span><br><span class="line"><span class="string">                :func:`propagate`.</span></span><br><span class="line"><span class="string">            size (tuple, optional): The size :obj:`(N, M)` of the assignment</span></span><br><span class="line"><span class="string">                matrix in case :obj:`edge_index` is a :obj:`LongTensor`.</span></span><br><span class="line"><span class="string">                If set to :obj:`None`, the size will be automatically inferred</span></span><br><span class="line"><span class="string">                and assumed to be quadratic.</span></span><br><span class="line"><span class="string">                This argument is ignored in case :obj:`edge_index` is a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`. (default: :obj:`None`)</span></span><br><span class="line"><span class="string">            **kwargs: Any additional data which is needed to construct and</span></span><br><span class="line"><span class="string">                aggregate messages, and to update node embeddings.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        size = self.__check_input__(edge_index, size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run "fused" message and aggregation (if applicable).</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(edge_index, SparseTensor) <span class="keyword">and</span> self.fuse</span><br><span class="line">                <span class="keyword">and</span> <span class="keyword">not</span> self.__explain__):</span><br><span class="line">            coll_dict = self.__collect__(self.__fused_user_args__, edge_index,</span><br><span class="line">                                         size, kwargs)</span><br><span class="line">            print(<span class="string">"Using self-defined message-passing"</span>)</span><br><span class="line">            msg_aggr_kwargs = self.inspector.distribute(</span><br><span class="line">                <span class="string">'message_and_aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Otherwise, run both functions in separation.</span></span><br><span class="line">        <span class="keyword">elif</span> isinstance(edge_index, Tensor) <span class="keyword">or</span> <span class="keyword">not</span> self.fuse:</span><br><span class="line">            coll_dict = self.__collect__(self.__user_args__, edge_index, size,</span><br><span class="line">                                         kwargs)</span><br><span class="line"></span><br><span class="line">            msg_kwargs = self.inspector.distribute(<span class="string">'message'</span>, coll_dict)</span><br><span class="line">            out = self.message(**msg_kwargs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># For `GNNExplainer`, we require a separate message and aggregate</span></span><br><span class="line">            <span class="comment"># procedure since this allows us to inject the `edge_mask` into the</span></span><br><span class="line">            <span class="comment"># message passing computation scheme.</span></span><br><span class="line">            <span class="keyword">if</span> self.__explain__:</span><br><span class="line">                edge_mask = self.__edge_mask__.sigmoid()</span><br><span class="line">                <span class="comment"># Some ops add self-loops to `edge_index`. We need to do the</span></span><br><span class="line">                <span class="comment"># same for `edge_mask` (but do not train those).</span></span><br><span class="line">                <span class="keyword">if</span> out.size(self.node_dim) != edge_mask.size(<span class="number">0</span>):</span><br><span class="line">                    loop = edge_mask.new_ones(size[<span class="number">0</span>])</span><br><span class="line">                    edge_mask = torch.cat([edge_mask, loop], dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">assert</span> out.size(self.node_dim) == edge_mask.size(<span class="number">0</span>)</span><br><span class="line">                out = out * edge_mask.view([<span class="number">-1</span>] + [<span class="number">1</span>] * (out.dim() - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            aggr_kwargs = self.inspector.distribute(<span class="string">'aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.aggregate(out, **aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        <span class="comment"># note: norm is in shape of (number of edge, )</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line">        print(<span class="string">"Get degree Shape: "</span>, edge_index.shape)</span><br><span class="line">        print(<span class="string">"Norm Shape: "</span>,norm.shape)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="comment"># Convert edge index to a sparse adjacency matrix representation, with row = from nodes, col = to nodes. </span></span><br><span class="line">        <span class="comment"># When value =  1 in adjacency matrix, it indicates two nodes are adjacent.</span></span><br><span class="line">        <span class="comment"># adjmat = SparseTensor(row=edge_index[0], col=edge_index[1], value=torch.ones(edge_index.shape[1]))</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这里 adjacency matrix 的值从1 变成 normalization 的值，方便乘法计算</span></span><br><span class="line">        adjmat = SparseTensor(row=edge_index[<span class="number">0</span>], col=edge_index[<span class="number">1</span>], value=norm)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 此处传的不再是edge_idex，而是SparseTensor类型的Adjancency Matrix</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(adjmat, x=x, norm=norm, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, norm, deg_i=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j * deg_i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">"`aggregate` is called"</span>)</span><br><span class="line">        <span class="keyword">return</span> super().aggregate(inputs, index, ptr=ptr, dim_size=dim_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message_and_aggregate</span><span class="params">(self, adj_t, x, norm,deg)</span>:</span></span><br><span class="line">        <span class="comment"># note: </span></span><br><span class="line">        <span class="comment"># adj_t: adjacency matrix</span></span><br><span class="line">        <span class="comment"># norm: normalization coefficient 1/sqrt(deg_i)*sqrt(deg_j)</span></span><br><span class="line">        <span class="comment"># number of '1' in adj_t = length of norm</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## Print something to debug</span></span><br><span class="line">        <span class="comment">#print('`message_and_aggregate` is called')</span></span><br><span class="line">        <span class="comment">#print("adj_t: ",adj_t)</span></span><br><span class="line">        <span class="comment">#print("deg:", deg)</span></span><br><span class="line">        </span><br><span class="line">        adj_t = adj_t.to_dense()</span><br><span class="line">        N = len(adj_t)</span><br><span class="line">        out = []</span><br><span class="line">        x0 = x[:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">            <span class="comment"># 计算每个 xi 的neighbor传过来的信息的平均值</span></span><br><span class="line">            x_sum = torch.matmul(x.T,adj_t[i])</span><br><span class="line">            x_avg = x_sum/deg[i]</span><br><span class="line">            out.append(x_avg)</span><br><span class="line">        out = torch.stack(out)</span><br><span class="line">        <span class="keyword">return</span> [out, x0]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, inputs, deg)</span>:</span></span><br><span class="line">        print(<span class="string">"Update result"</span>)</span><br><span class="line">        print(<span class="string">"Degree"</span>,deg)</span><br><span class="line">        <span class="comment"># resnet的结构</span></span><br><span class="line">        x0 = inputs[<span class="number">1</span>]</span><br><span class="line">        output = self.relu(inputs[<span class="number">0</span>]) + x0</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br></pre></td></tr></table></figure>

<pre><code>Get degree Shape:  torch.Size([2, 13264])
Norm Shape:  torch.Size([13264])
Using self-defined message-passing
Update result
Degree tensor([[4.],
        [4.],
        [6.],
        ...,
        [2.],
        [5.],
        [5.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h_nodes</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[ 1.1262e-04, -6.0657e-02, -2.5644e-02,  ...,  1.2791e-02,
          2.4094e-02,  8.4488e-02],
        [ 9.5781e-02,  3.0109e-02,  1.0536e-01,  ...,  5.9062e-02,
          6.5623e-02,  2.2322e-02],
        [ 1.1685e-01,  1.9822e-02,  1.5696e-01,  ...,  7.2434e-02,
         -1.8062e-02, -2.3522e-02],
        ...,
        [ 8.3955e-02, -1.9041e-03,  8.8832e-02,  ...,  8.1169e-02,
         -2.3039e-02,  7.6098e-02],
        [-6.5679e-03,  9.7862e-03,  3.8410e-02,  ..., -3.0759e-02,
         -5.3772e-03,  1.5986e-01],
        [ 1.6175e-01, -2.3304e-02, -5.7581e-02,  ...,  3.2008e-02,
         -1.7487e-02,  3.8593e-02]], grad_fn=&lt;AddBackward0&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/GNN/">GNN</a><a class="link-muted mr-2" rel="tag" href="/tags/Graph/">Graph</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://ppoffice.github.io/hexo-theme-icarus-categorites-Plugins/Share/" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/06/15/GNN-1-Basic/"><span class="level-item">GNN-1-Basic</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "kvXCKmDNxnA2486N29e5cP7i-MdYXbMMI",
            appKey: "0Lv5b0SqotzkGHQvD64u4AKo",
            
            avatar: "mm",
            
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "en",
            
            highlight: true,
            
            
            
            
            
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://github.com/wenkangwei" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Data-Collection/"><span class="level-start"><span class="level-item">Data Collection</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Data-Structure/Sorting/"><span class="level-start"><span class="level-item">Sorting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/Accuracy-Improvement/"><span class="level-start"><span class="level-item">Accuracy Improvement</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Parallel-Computing/"><span class="level-start"><span class="level-item">Parallel Computing</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/PySpark/"><span class="level-start"><span class="level-item">PySpark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Recommendation-System/"><span class="level-start"><span class="level-item">Recommendation System</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Report/"><span class="level-start"><span class="level-item">Report</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Searching/"><span class="level-start"><span class="level-item">Searching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Searching/Data-Strucure/"><span class="level-start"><span class="level-item">Data Strucure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Statistic/"><span class="level-start"><span class="level-item">Statistic</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Amdahl-s-Law/"><span class="tag">Amdahl&#039;s Law</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Backpropagation/"><span class="tag">Backpropagation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bagging/"><span class="tag">Bagging</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BeautifulSoup/"><span class="tag">BeautifulSoup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Tree/"><span class="tag">Binary Tree</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Blending/"><span class="tag">Blending</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting/"><span class="tag">Boosting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting-Machine/"><span class="tag">Boosting Machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BuckSort/"><span class="tag">BuckSort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Collaborative-Filtering/"><span class="tag">Collaborative Filtering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Confusion-Metric/"><span class="tag">Confusion Metric</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Convolution-Neural-Network/"><span class="tag">Convolution Neural Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Validation/"><span class="tag">Cross Validation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/D3-js/"><span class="tag">D3.js</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DCN/"><span class="tag">DCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIN/"><span class="tag">DIN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Analysis/"><span class="tag">Data Analysis</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Mining/"><span class="tag">Data Mining</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Datawhale-Team-Learning/"><span class="tag">Datawhale Team Learning</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepFM/"><span class="tag">DeepFM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dropout/"><span class="tag">Dropout</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ensemble-Learning/"><span class="tag">Ensemble Learning</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GNN/"><span class="tag">GNN</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Holdout/"><span class="tag">Holdout</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hypothesis-Test/"><span class="tag">Hypothesis Test</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Icarus/"><span class="tag">Icarus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Independence-Test/"><span class="tag">Independence Test</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/K-Mean-Clustering/"><span class="tag">K-Mean Clustering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KMean-Clustering/"><span class="tag">KMean Clustering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LGBM/"><span class="tag">LGBM</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Evaluation/"><span class="tag">Model Evaluation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Selection/"><span class="tag">Model Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Natural-Language-Representations/"><span class="tag">Natural Language Representations</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nature-Language-Processing/"><span class="tag">Nature Language Processing</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Negative-Sampling/"><span class="tag">Negative Sampling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NeuralFM/"><span class="tag">NeuralFM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/P-value/"><span class="tag">P-value</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Parallel-Computing/"><span class="tag">Parallel Computing</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Parallel-Speedup/"><span class="tag">Parallel Speedup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PySpark/"><span class="tag">PySpark</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROC-curve/"><span class="tag">ROC curve</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommendation-System/"><span class="tag">Recommendation System</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regular-Expression/"><span class="tag">Regular Expression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sorting/"><span class="tag">Sorting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stacking/"><span class="tag">Stacking</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Traversal/"><span class="tag">Traversal</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-Learning/"><span class="tag">Unsupervised Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Variable-Selection/"><span class="tag">Variable Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web-Scrapping/"><span class="tag">Web Scrapping</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-and-Deep/"><span class="tag">Wide and Deep</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-and-Deep-Model/"><span class="tag">Wide and Deep Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-Deep-Model/"><span class="tag">Wide&amp;Deep Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-vector/"><span class="tag">Word vector</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/binary-search/"><span class="tag">binary search</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bubble-sort/"><span class="tag">bubble sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/commands/"><span class="tag">commands</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/insertion-sort/"><span class="tag">insertion sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/merge-sort/"><span class="tag">merge sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/non-parametric-learning/"><span class="tag">non-parametric learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quick-sort/"><span class="tag">quick sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/review/"><span class="tag">review</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-06-18T23:00:02.000Z">2021-06-18</time></p><p class="title is-6"><a class="link-muted" href="/2021/06/18/GNN-2-MessagePassing/">GNN-2-MessagePassing</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-06-16T03:16:25.000Z">2021-06-15</time></p><p class="title is-6"><a class="link-muted" href="/2021/06/15/GNN-1-Basic/">GNN-1-Basic</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-05-20T21:29:11.000Z">2021-05-20</time></p><p class="title is-6"><a class="link-muted" href="/2021/05/20/Recommendation-System-6-DCN/">Recommendation System-6-DCN</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-05-18T07:03:39.000Z">2021-05-18</time></p><p class="title is-6"><a class="link-muted" href="/2021/05/18/ensemble-learning-project-HappinessPrediction/">ensemble-learning-project-HappinessPrediction</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-05-13T05:48:29.000Z">2021-05-13</time></p><p class="title is-6"><a class="link-muted" href="/2021/05/13/ensemble-learning-Stacking/">ensemble-learning-Stacking</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/06/"><span class="level-start"><span class="level-item">June 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/avatar.jpg" alt="Wenkang Wei"></figure><p class="title is-size-4 is-block line-height-inherit">Wenkang Wei</p><p class="is-size-6 is-block">computer engineering| machine learning</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Clemson,SC</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">37</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">18</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">69</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wenkangwei" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wenkangwei"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/wenkang-wei-588811167"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a></div></div></div><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#GNN-2-Message-Passing-消息传递神经网络"><span class="mr-2">1</span><span>GNN-2-Message Passing 消息传递神经网络</span></a><ul class="menu-list"><li><a class="is-flex" href="#1-Introduction"><span class="mr-2">1.1</span><span>1. Introduction</span></a></li><li><a class="is-flex" href="#2-How-Message-Passing-works"><span class="mr-2">1.2</span><span>2.How Message Passing works</span></a></li><li><a class="is-flex" href="#3-MessagePassing-Class-in-PyTorch-Geometric"><span class="mr-2">1.3</span><span>3. MessagePassing Class in PyTorch Geometric</span></a></li><li><a class="is-flex" href="#4-Coding-Practice"><span class="mr-2">1.4</span><span>4. Coding Practice</span></a><ul class="menu-list"><li><a class="is-flex" href="#4-1-基于-Message-Passing的泛式-框架-搭建Graph-Convolution-Network-GCN"><span class="mr-2">1.4.1</span><span>4.1 基于 Message Passing的泛式(框架)搭建Graph Convolution Network (GCN)</span></a></li><li><a class="is-flex" href="#4-2-Overwrite-methods-messsage-aggregate-update"><span class="mr-2">1.4.2</span><span>4.2 Overwrite methods: messsage, aggregate, update</span></a></li></ul></li><li><a class="is-flex" href="#5-Assignment"><span class="mr-2">1.5</span><span>5. Assignment</span></a><ul class="menu-list"><li><a class="is-flex" href="#5-1-Message-Passing-机制总结"><span class="mr-2">1.5.1</span><span>5.1 Message Passing 机制总结</span></a></li><li><a class="is-flex" href="#5-2-用MessagePassing-这个BaseClass去实现一个-我自定义的GCN-layer"><span class="mr-2">1.5.2</span><span>5.2 用MessagePassing 这个BaseClass去实现一个 我自定义的GCN layer</span></a></li></ul></li></ul></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/icon.png" alt="Wenkang&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2021 Wenkang Wei</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://github.com/wenkangwei/wenkangwei.github.io`',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>