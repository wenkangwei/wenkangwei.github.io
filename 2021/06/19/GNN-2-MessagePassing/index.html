<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GNN-2-MessagePassing - Wenkang&#039;s Blog</title><meta description=""><meta property="og:type" content="article"><meta property="og:title" content="GNN-2-MessagePassing"><meta property="og:url" content="https://github.com/wenkangwei/"><meta property="og:site_name" content="Wenkang&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="article:published_time" content="2021-06-18T23:00:02.000Z"><meta property="article:modified_time" content="2021-06-19T19:27:12.136Z"><meta property="article:author" content="Wenkang Wei"><meta property="article:tag" content="GNN"><meta property="article:tag" content="Graph"><meta property="twitter:card" content="summary"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://github.com/wenkangwei/wenkangwei.github.io%60/2021/06/19/GNN-2-MessagePassing/"},"headline":"Wenkang's Blog","image":[],"datePublished":"2021-06-18T23:00:02.000Z","dateModified":"2021-06-19T19:27:12.136Z","author":{"@type":"Person","name":"Wenkang Wei"},"description":""}</script><link rel="canonical" href="https://github.com/wenkangwei/wenkangwei.github.io%60/2021/06/19/GNN-2-MessagePassing/"><link rel="icon" href="/images/icon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/icon.png" alt="Wenkang&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-06-18T23:00:02.000Z" title="2021-06-18T23:00:02.000Z">2021-06-18</time><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a></span><span class="level-item">an hour read (About 10012 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span> visits</span></div></div><h1 class="title is-3 is-size-4-mobile">GNN-2-MessagePassing</h1><div class="content"><img src=https://panonit.com/sites/default/files/Message-passing-in-oop.png>

<a id="more"></a>


<h1 id="GNN-2-Message-Passing-消息传递神经网络"><a href="#GNN-2-Message-Passing-消息传递神经网络" class="headerlink" title="GNN-2-Message Passing 消息传递神经网络"></a>GNN-2-Message Passing 消息传递神经网络</h1><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>在图神经网络里面，在对数据和样本之间的关系进行建模得到图的edge， node之后，我们需要在图里面把每个节点的信息根据它的neighbor的信息进行更新，从而达到node的信息更新和节点特征(Node Representation)的特征表达。而这个把node节点信息相互传递从而更新节点表征的方法也叫Message Passing。<br>MessagePassing是一种聚合邻接节点信息来更新中心节点信息的范式，它将卷积算子推广到了不规则数据领域，实现了图与神经网络的连接。消息传递范式因为简单、强大的特性，于是被人们广泛地使用。遵循消息传递范式的图神经网络被称为消息传递图神经网络。</p>
<p>这一节里面我们讨论和实践 图神经网络一下几点:</p>
<ul>
<li><p>Message Passing 的原理</p>
</li>
<li><p>PyG (PyTorch Geometric)里面的MessagePassing类的理解和改写</p>
</li>
<li><p>通过MessagePassing, GCNConv 搭建Graph Convolution Neural network (GCN) 并通过实际的数据进行训练</p>
</li>
<li><p>对MessagePassing的基类函数如 aggregation， update， 的method进行理解和使用</p>
</li>
<li><p><strong>Jupyter Notebook source code</strong> 可以看这里: <a href="https://github.com/wenkangwei/Datawhale-Team-Learning/blob/main/GNN/Task-2-MessagePassing/GNN-Task-2-MessagePassing.ipynb">https://github.com/wenkangwei/Datawhale-Team-Learning/blob/main/GNN/Task-2-MessagePassing/GNN-Task-2-MessagePassing.ipynb</a></p>
</li>
<li><p>注：这篇文章参考了<a href="https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/4-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md">datawhale教学文档</a>, Torch Geometric 官方文档， <a href="https://cse.msu.edu/~mayao4/dlg_book/chapters/">Deep Learning on Graph</a>, 并添加了自己一些想法。</p>
</li>
</ul>
<h2 id="2-How-Message-Passing-works"><a href="#2-How-Message-Passing-works" class="headerlink" title="2.How Message Passing works"></a>2.How Message Passing works</h2><ul>
<li><strong>Message Passing的基本思路</strong></li>
</ul>
<p>以图片为例，如果我们的任务是node prediction去预测node A的特征值/node representation，那么图片里node A就是target node。然后 MessagePassing的过程如下</p>
<ol>
<li>图中黄色方框部分内容的是一次邻居节点信息传递到中心节点的过程：B节点的邻接节点（A,C）的信息经过变换后聚合到B节点，接着B节点信息与邻居节点聚合信息一起经过变换得到B节点的新的节点信息。同时，分别如红色和绿色方框部分所示，同样的过程，C、D节点的信息也被更新。实际上，同样的过程在所有节点上都进行了一遍，所有节点的信息都更新了一遍。 每个node的值是同时更新的</li>
<li>把步骤1 的“邻居节点信息传递到中心节点的过程”进行多次。如图中蓝色方框部分所示，A节点的邻接节点（B,C,D）的已经发生过一次更新的节点信息，经过变换、聚合、再变换产生了A节点第二次更新的节点信息。多次更新后的节点信息就作为节点表征。</li>
<li>一句话总结就是每次都把图里面的node的信息根据邻居节点进行更新，并多次把图的信息不断刷新得到Node representation。</li>
</ol>
<img src=https://raw.githubusercontent.com/wenkangwei/team-learning-nlp/master/GNN/Markdown%E7%89%88%E6%9C%AC/images/image-20210516110407207.png>


<ul>
<li><strong>Message Passing GNN 的泛式</strong></li>
</ul>
<p>MessagePassing图神经网络遵循上述的“聚合邻接节点信息来更新中心节点信息的过程”，来生成节点表征。<strong>Message Passing GNN的通用公式可以描述为</strong></p>
<p>$$<br>\mathbf{x}_ i^{(k)} = \gamma^{(k)} ( \mathbf{x}_ i^{(k-1)}, \square_{j \in \mathcal{N}(i)} , \phi^{(k)}(\mathbf{x}_ i^{(k-1)}, \mathbf{x}_ j^{(k-1)},\mathbf{e}_{j,i}) ),<br>$$</p>
<p>根据<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html">官方文档</a> 以及<a href="https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html#creating-message-passing-networks">CREATING MESSAGE PASSING NETWORKS</a>, 我们定义</p>
<ul>
<li><p>$\mathbf{x}^{(k-1)}_i\in\mathbb{R}^F$表示神经网络的$(k-1)$层中节点$i$的节点表征</p>
</li>
<li><p>$\mathbf{e}_{j,i} \in \mathbb{R}^D$ 表示从节点$j$到节点$i$的边的属性信息。</p>
</li>
<li><p>$\square$表示<strong>可微分</strong>的、具有排列不变性（<strong>函数输出结果与输入参数的排列无关</strong>）的函数, 比如aggregation 函数。比如sum， mean, min等函数和输入的参数顺序无关的函数。</p>
</li>
<li><p>$\gamma$ : <strong>可微分可导</strong>的update 函数，比如MLPs（多层感知器）</p>
</li>
<li><p>$\phi$: <strong>可微分可导</strong>的message 函数，比如MLPs（多层感知器）和 linear Projection等</p>
</li>
<li><p><strong>Note:</strong></p>
<ol>
<li><p>神经网络的生成节点表征的操作称为节点嵌入（Node Embedding），节点表征也可以称为节点嵌入。<strong>这里考虑节点嵌入只代指神经网络生成节点表征的操作</strong>。</p>
</li>
<li><p>未经过训练的图神经网络生成的节点表征还不是好的节点表征，好的节点表征可用于衡量节点之间的相似性。通过监督学习对图神经网络做很好的训练，图神经网络才可以生成好的节点表征。我们将在<a href="5-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%8A%82%E7%82%B9%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0.md">第5节</a>介绍此部分内容。</p>
</li>
<li><p>节点表征与节点属性的区分：遵循被广泛使用的约定，此次组队学习我们也约定，节点属性<code>data.x</code>是节点的第0层(GNN输入层)节点表征，第$h$层的节点表征经过一次的节点间信息传递产生第$h+1$层的节点表征。不过，节点属性不单指<code>data.x</code>，广义上它就指节点的属性，如节点的度(in-degree, out-degree)等。</p>
</li>
</ol>
</li>
</ul>
<h2 id="3-MessagePassing-Class-in-PyTorch-Geometric"><a href="#3-MessagePassing-Class-in-PyTorch-Geometric" class="headerlink" title="3. MessagePassing Class in PyTorch Geometric"></a>3. MessagePassing Class in PyTorch Geometric</h2><h3 id="3-1-MessagePassing-的Base-Class-函数"><a href="#3-1-MessagePassing-的Base-Class-函数" class="headerlink" title="3.1 MessagePassing 的Base Class 函数"></a>3.1 MessagePassing 的Base Class 函数</h3><p>Pytorch Geometric(PyG)提供了MessagePassing基类，它封装了“消息传递”的运行流程。通过继承MessagePassing基类，可以方便地构造消息传递图神经网络。构造一个最简单的消息传递图神经网络类，我们只需定义message()方法（ 𝜙(..) ）、update()方法（ 𝛾(..) ），以及使用的消息聚合方案（aggr=”add”、aggr=”mean”或aggr=”max”。<strong>MessagePassing Base Class中这里最重要的3个函数是：</strong></p>
<ul>
<li><code>MessagePassing.aggregate(...)</code>：用于处理聚集到节点的信息的函数</li>
<li><code>MessagePassing.message(...)</code>：用于搭建传送到 node i的节点消息，相对于𝜙(..)函数</li>
<li><code>MessagePassing.update(aggr_out, ...)</code>: 用于更新节点的信息，相对于𝛾(..)</li>
</ul>
<p><strong>以下是一些常用函数的解释:</strong></p>
<ul>
<li><p><code>MessagePassing(aggr=&quot;add&quot;, flow=&quot;source_to_target&quot;, node_dim=-2)</code>: </p>
<ul>
<li><code>aggr</code>: aggregation function聚合函数的选项, 可以用 (“add”, “mean” or “max”)</li>
<li><code>flow</code>: 信息传递方向 (either “source_to_target” or “target_to_source”)</li>
<li><code>node_dim</code>：定义沿着哪个维度传播，默认值为-2，也就是节点表征张量（data.x, Tensor）的哪一个维度是节点维度。节点表征张量x形状为[num_nodes, num_features]，其第0维度/columns（也是第-2维度）是节点维度(节点的个数)，其第1维度（也是第-1维度）是节点表征维度，所以我们可以设置node_dim=-2。</li>
</ul>
</li>
<li><p><code>MessagePassing.propagate(edge_index, size=None, **kwargs)</code>: </p>
<ul>
<li><code>edge_index</code>: 一个matrix存放每条edge 的索引信息(起始和终止的node的index)</li>
<li><code>size</code>: 基于非对称的邻接矩阵进行消息传递（当图为二部图时），需要传递参数size=(N, M)。如果size=None, 默认邻接矩阵是对称的</li>
<li><code>**kwargs</code>：图的其他特征</li>
</ul>
</li>
<li><p><code>MessagePassing.message(...)</code>：</p>
<ul>
<li>首先确定要给节点$i$传递消息的边的集合：<ul>
<li>如果<code>flow=&quot;source_to_target&quot;</code>，则是$(j,i) \in \mathcal{E}$的边的集合；</li>
<li>如果<code>flow=&quot;target_to_source&quot;</code>，则是$(i,j) \in \mathcal{E}$的边的集合。</li>
</ul>
</li>
<li>接着为各条边创建要传递给节点$i$的消息，即实现$\phi$函数。</li>
<li><code>MessagePassing.message(...)</code>方法可以接收传递给<code>MessagePassing.propagate(edge_index, size=None, **kwargs)</code>方法的所有参数，我们在<code>message()</code>方法的参数列表里定义要接收的参数，例如我们要接收<code>x,y,z</code>参数，则我们应定义<code>message(x,y,z)</code>方法。</li>
<li>传递给<code>propagate()</code>方法的参数，如果是节点的属性的话，可以被拆分成属于中心节点的部分和属于邻接节点的部分，只需在变量名后面加上<code>_i</code>或<code>_j</code>。例如，我们自己定义的<code>meassage</code>方法包含参数<code>x_i</code>，那么首先<code>propagate()</code>方法将节点表征拆分成中心节点表征和邻接节点表征，接着<code>propagate()</code>方法调用<code>message</code>方法并传递中心节点表征给参数<code>x_i</code>。而如果我们自己定义的<code>meassage</code>方法包含参数<code>x_j</code>，那么<code>propagate()</code>方法会传递邻接节点表征给参数<code>x_j</code>。</li>
<li>我们用$i$表示“消息传递”中的中心节点，用$j$表示“消息传递”中的邻接节点。</li>
</ul>
</li>
<li><p><code>MessagePassing.aggregate(...)</code>：</p>
<ul>
<li>将从源节点传递过来的消息聚合在目标节点上，一般可选的聚合方式有<code>sum</code>, <code>mean</code>和<code>max</code>。</li>
</ul>
</li>
<li><p><code>MessagePassing.message_and_aggregate(...)</code>：</p>
<ul>
<li>在一些场景里，邻接节点信息变换和邻接节点信息聚合这两项操作可以融合在一起，那么我们可以在此方法里定义这两项操作，从而让程序运行更加高效。</li>
</ul>
</li>
<li><p><code>MessagePassing.update(aggr_out, ...)</code>: </p>
<ul>
<li>为每个节点$i \in \mathcal{V}$更新节点表征，即实现$\gamma$函数。此方法以<code>aggregate</code>方法的输出为第一个参数，并接收所有传递给<code>propagate()</code>方法的参数。</li>
</ul>
</li>
</ul>
<h3 id="3-2-MessagePassing-的Base-Class-函数"><a href="#3-2-MessagePassing-的Base-Class-函数" class="headerlink" title="3.2 MessagePassing 的Base Class 函数"></a>3.2 MessagePassing 的Base Class 函数</h3><h4 id="3-2-1-propagate-函数的输入"><a href="#3-2-1-propagate-函数的输入" class="headerlink" title="3.2.1 propagate 函数的输入"></a>3.2.1 propagate 函数的输入</h4><p>propagate 函数的输入 有edge_index, x (node embedding matrix), 以及其他自定义的输入参数(degree, norm之类的)。其中edge_index的储存形式如下<br>$$<br>\mathbf{Edge index}=[\begin{array}{lllll}<br>    [0 &amp; 0&amp; 1&amp; 4&amp;..8] \\<br>    [0&amp; 1&amp; 4&amp; 1&amp; ..9] \\<br>    \end{array}]<br>$$<br>其中Edge_index的shape = [2, amount of edge]. Edge_index[0]第一行是source node的index， Edge_index[1]第二行是target node的index. </p>
<p><strong>Note</strong></p>
<ol>
<li>如果edge_index 用 torch tensor来储存，那么propagate函数会分别调用message, aggregate的函数</li>
<li>如果edge_index 用 torch_sparse的SparseTensor类来储存，那么propagate函数会调用message_and_aggregate的函数而不是两个单独的函数</li>
<li><strong>当edge_index, x(node embedding)输入到propagate后，它会自动通过 __collect__()函数 把输入解析得到以下参数:</strong><ul>
<li><strong>如果self.flow=”source_to_target”:</strong><ul>
<li><p><strong>x_i</strong>: edge_index的target node的index列表(edge_index[1])对应的node embedding向量列表。<br>比如 edge_index的target node列表是 edge_index[1], length = E, 而node embedding的维度为dim, 那么 x_i =x[edge_index[1]]是edge_index[1]所对应的embedding列表， x_i的shape= [E, dim]。<br>举个例子就是 target node 的索引列表是 edge_index[1] = [0, 1, 2]而 E=3, dim=2, 那么 x_i = [[0.5,0.6],[0.1,0.22],[0.2,0.3]]。x_i里面的每一行分别对应target node 0, 1,2的node embedding向量</p>
</li>
<li><p><strong>deg_i</strong>: edge_index的target node的index列表对应的degree列表。这个和x_i同理</p>
</li>
<li><p><strong>x_j</strong>：edge_index的source node的edge_index[0]列表对应的node embedding向量列表。</p>
</li>
<li><p><strong>deg_j</strong>: edge_index的source node的edge_index[0]列表对应的degree列表。这个和x_j同理</p>
</li>
</ul>
</li>
<li><strong>如果flow=”target_to_source” 那么有_ i后缀代表source,  _ j后缀代表target node</strong></li>
</ul>
</li>
<li>在得到target node的edge_index和 对应的source node的node embedding vectors之后，我们就可以把每个target node对应的所有node embedding向量聚合一起得到target node的信息集合用于搭建 message了<h4 id="3-2-2-message-函数的输入"><a href="#3-2-2-message-函数的输入" class="headerlink" title="3.2.2 message 函数的输入"></a>3.2.2 message 函数的输入</h4>message 函数输入一般包括: x_i, x_j, deg_i, deg_j, edge_index以及其他自定义的参数输入</li>
</ol>
<h4 id="3-2-3-aggregate-函数的输入"><a href="#3-2-3-aggregate-函数的输入" class="headerlink" title="3.2.3 aggregate 函数的输入"></a>3.2.3 aggregate 函数的输入</h4><p>aggregate 函数输入除了有 <strong>inputs (来自message函数的输入)</strong> 外 一般还包括: inputs, x_i, x_j, deg_i, deg_j, edge_index以及其他自定义的参数输入。</p>
<h4 id="3-2-4-message-and-aggregate-函数的输入"><a href="#3-2-4-message-and-aggregate-函数的输入" class="headerlink" title="3.2.4 message_and_aggregate 函数的输入"></a>3.2.4 message_and_aggregate 函数的输入</h4><p>message_and_aggregate 函数输入 一般还包括: x_i, x_j, deg_i, deg_j, edge_index以及其他自定义的参数输入。</p>
<h4 id="3-2-5-update-函数的输入"><a href="#3-2-5-update-函数的输入" class="headerlink" title="3.2.5 update 函数的输入"></a>3.2.5 update 函数的输入</h4><p>update 函数输入包括inputs以及其他自定义的参数输入。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="4-Coding-Practice"><a href="#4-Coding-Practice" class="headerlink" title="4. Coding Practice"></a>4. Coding Practice</h2><h3 id="4-1-基于-Message-Passing的泛式-框架-搭建Graph-Convolution-Network-GCN"><a href="#4-1-基于-Message-Passing的泛式-框架-搭建Graph-Convolution-Network-GCN" class="headerlink" title="4.1 基于 Message Passing的泛式(框架)搭建Graph Convolution Network (GCN)"></a>4.1 基于 Message Passing的泛式(框架)搭建Graph Convolution Network (GCN)</h3><p>根据PyG的官方文档，**<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv"><code>GCNConv</code></a>** 的公式是<br>$$<br>\mathbf{x}_ i^{(k)} = \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_ j^{(k-1)} ),<br>$$</p>
<p>矩阵的形式是<br>$$<br>\mathbf{X}^{(k)}  = \mathbf{D}^{-0.5}\mathbf{A}\mathbf{D}^{-0.5}\mathbf{X}^{(k-1)}\mathbf{\Theta}<br>$$</p>
<p>其中，$\mathbf{x}_i$ 的节点的特征是由它的近邻的node的信息(包括node i自己)进行更新，所以计算时j是节点i的邻居(包括节点i本身)的子集里面的node。 邻接节点的表征$\mathbf{x}_j^{(k-1)}$首先通过与权重矩阵$\mathbf{\Theta}$相乘进行变换，然后按端点的度$\deg(i), \deg(j)$进行归一化处理，最后进行求和。这个公式可以分为以下几个步骤：</p>
<ol>
<li>向邻接矩阵添加自环边。</li>
<li>对节点表征做线性转换。</li>
<li>计算归一化系数。</li>
<li>归一化邻接节点的节点表征。</li>
<li>将相邻节点表征相加（”求和 “聚合）。</li>
</ol>
<p>步骤1-3通常是在消息传递发生之前计算的。步骤4-5可以使用<a href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.message_passing.MessagePassing"><code>MessagePassing</code></a>基类轻松处理。该层的全部实现如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>)  <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        <span class="comment"># Adds a self-loop (i,i)∈E to every node i∈V in the graph given by edge_index.</span></span><br><span class="line">        <span class="comment"># In case the graph is weighted, self-loops will be added with edge weights denoted by fill_value.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization: 1/sqrt(degree(i)) * 1/sqrt(degree(j))</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == float(<span class="string">'inf'</span>)] = <span class="number">0</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, norm)</span>:</span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## download data to current directory</span></span><br><span class="line"><span class="comment">#! wget https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'./dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># GCNConv: </span></span><br><span class="line"><span class="comment">#in_channels: dimension of input vector of linear layer</span></span><br><span class="line"><span class="comment"># out_channels: dimension of output vector of linear layer</span></span><br><span class="line"><span class="comment">#Note: the linear transform is performed before message passing to reduce the dimension of node representation</span></span><br><span class="line"><span class="comment"># After message passing, the amount of nodes doesn't change</span></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># data.x: a matrix with each row representing the data in a node</span></span><br><span class="line"><span class="comment"># data.edge_index: matrix with shape [2, number of edges], each column representing edge from node to another node, value=index of node</span></span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line">print(h_nodes.shape)</span><br></pre></td></tr></table></figure>

<pre><code>torch.Size([2708, 64])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.x.shape</span><br></pre></td></tr></table></figure>




<pre><code>torch.Size([2708, 1433])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="4-2-Overwrite-methods-messsage-aggregate-update"><a href="#4-2-Overwrite-methods-messsage-aggregate-update" class="headerlink" title="4.2 Overwrite methods: messsage, aggregate, update"></a>4.2 Overwrite methods: messsage, aggregate, update</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        print(<span class="string">"Before self-loop:"</span>,edge_index.shape)</span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line">        print(<span class="string">"After self-loop:"</span>,edge_index.shape)</span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="comment"># Convert edge index to a sparse adjacency matrix representation, with row = from nodes, col = to nodes, value = 0 or 1 indicating if</span></span><br><span class="line">        <span class="comment"># two nodes are adjacent.</span></span><br><span class="line">        adjmat = SparseTensor(row=edge_index[<span class="number">0</span>], col=edge_index[<span class="number">1</span>], value=torch.ones(edge_index.shape[<span class="number">1</span>]))</span><br><span class="line">        <span class="comment">#print("Adjacency matrix:",adjmat)</span></span><br><span class="line">        <span class="comment"># 此处传的不再是edge_idex，而是SparseTensor类型的Adjancency Matrix</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(adjmat, x=x, norm=norm, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, norm, deg_i)</span>:</span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j * deg_i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">"`aggregate` is called"</span>)</span><br><span class="line">        <span class="keyword">return</span> super().aggregate(inputs, index, ptr=ptr, dim_size=dim_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message_and_aggregate</span><span class="params">(self, adj_t, x, norm)</span>:</span></span><br><span class="line">        print(<span class="string">'`message_and_aggregate` is called'</span>)</span><br><span class="line">        <span class="comment"># 没有实现真实的消息传递与消息聚合的操作</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, inputs, deg)</span>:</span></span><br><span class="line">        print(deg)</span><br><span class="line">        <span class="keyword">return</span> inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line"><span class="comment"># print(h_nodes.shape)</span></span><br></pre></td></tr></table></figure>

<pre><code>Before self-loop: torch.Size([2, 10556])
After self-loop: torch.Size([2, 13264])
Adjacency matrix: SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),
             col=tensor([   0,  633, 1862,  ..., 1473, 2706, 2707]),
             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),
             size=(2708, 2708), nnz=13264, density=0.18%)
`message_and_aggregate` is called
tensor([[4.],
        [4.],
        [6.],
        ...,
        [2.],
        [5.],
        [5.]])
</code></pre>
<h2 id="5-Assignment"><a href="#5-Assignment" class="headerlink" title="5. Assignment"></a>5. Assignment</h2><h3 id="5-1-Message-Passing-机制总结"><a href="#5-1-Message-Passing-机制总结" class="headerlink" title="5.1 Message Passing 机制总结"></a>5.1 <strong>Message Passing 机制总结</strong></h3><p>Message Passing 根据上面讨论的的框架公式，在设计Message Passing 的流程可以归纳为以下几点:</p>
<ol>
<li>定义和选取 message 函数，𝜙(..)，并根据图的节点信息的输入($x_i^{k-1}, x_j^{k-1}, e_{i,j}$) 对输入进行变换(可导的，比如线性投映进行降维或乘上系数之类的)</li>
<li>定义和选取 aggregation 函数 $\square(..)$, 对转换后的信息进行邻居节点的信息聚合处理， 常用的有sum, mean, max之类的</li>
<li>定义和选取update()函数（ 𝛾(..) ），把原本的节点信息$x_i^{k-1}$ 和 聚合后的邻居节点信息($\square(..)$ 函数的输出)的信息进行整合，更新当前的节点信息得到$x_j^{k}$。</li>
</ol>
<p>用GCN的公式举个栗子，就是<br>$$<br>\mathbf{x}_ i^{(k)} = \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_ j^{(k-1)} ),<br>$$</p>
<ul>
<li><p>GCN里面的 $\frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} )$ 的操作，里面的$\mathbf{\Theta}$ 线性投映和用degree做normalization相对于是 𝜙(..)函数的message的搭建</p>
</li>
<li><p>而 $\sum_{j \in \mathcal{N}(i) \cup { i }}$ 这一步相对于把邻居节点(包括节点自己)的信息进行聚合, 相对于aggregation 函数 $\square(..)$</p>
</li>
<li><p>GCN这里因为在做了aggregation后没有用到 $x_i^{k-1}$信息，所以update()函数, 𝛾($x_i^{k-1}, \square(..)$) 可以看成直接输出(或者是$\square()$信息聚合后乘上1就输出)。𝛾(..)其实也可以替换为其他可导的的非线性函数比如 logistics， relu之类的。</p>
</li>
<li><p>至于MessagePassing 的Base Class里面的message_and_aggregate()可以看成是 $\square(\phi(x_i^{k-1}, x_j^{k-1}, e_{i,j}))$</p>
</li>
<li><p>MessagePassing 的Base Class里面的propagate()函数可以看成是对 $\gamma(x_i^{k-1}, \square(\phi(…)))$ 更新函数的封装。 这一点可以看看官方文档的<a href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.propagate">源码</a></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="5-2-用MessagePassing-这个BaseClass去实现一个GCN-layer"><a href="#5-2-用MessagePassing-这个BaseClass去实现一个GCN-layer" class="headerlink" title="5.2 用MessagePassing 这个BaseClass去实现一个GCN layer"></a>5.2 <strong>用MessagePassing 这个BaseClass去实现一个GCN layer</strong></h3><p>这里逐步实现实现一个GCN， 公式如下:</p>
<p>$$<br>\mathbf{x}_ i^{(k)} = \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_ j^{(k-1)} ),<br>$$</p>
<p>这里一些函数定义如下：</p>
<ul>
<li>$\phi(..)$: message函数GCN一样都是linear projection之后用degree进行normalization</li>
<li>$\square(..)$ : aggregate 函数用 add</li>
<li>$\gamma(..)$: update 函数是直接将aggregate后的结果输出</li>
</ul>
<h4 id="5-2-1-覆写message函数"><a href="#5-2-1-覆写message函数" class="headerlink" title="5.2.1 覆写message函数"></a>5.2.1 覆写message函数</h4><p>要求该函数接收消息传递源节点属性x、目标节点度d</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor, matmul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.lin2 = torch.nn.Linear(out_channels, out_channels)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(self, edge_index, size=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># I just copy the source copy from PyG website</span></span><br><span class="line">        <span class="string">r"""The initial call to start propagating messages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor` that defines the underlying</span></span><br><span class="line"><span class="string">                graph connectivity/message passing flow.</span></span><br><span class="line"><span class="string">                :obj:`edge_index` holds the indices of a general (sparse)</span></span><br><span class="line"><span class="string">                assignment matrix of shape :obj:`[N, M]`.</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its</span></span><br><span class="line"><span class="string">                shape must be defined as :obj:`[2, num_messages]`, where</span></span><br><span class="line"><span class="string">                messages from nodes in :obj:`edge_index[0]` are sent to</span></span><br><span class="line"><span class="string">                nodes in :obj:`edge_index[1]`</span></span><br><span class="line"><span class="string">                (in case :obj:`flow="source_to_target"`).</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`, its sparse indices</span></span><br><span class="line"><span class="string">                :obj:`(row, col)` should relate to :obj:`row = edge_index[1]`</span></span><br><span class="line"><span class="string">                and :obj:`col = edge_index[0]`.</span></span><br><span class="line"><span class="string">                The major difference between both formats is that we need to</span></span><br><span class="line"><span class="string">                input the *transposed* sparse adjacency matrix into</span></span><br><span class="line"><span class="string">                :func:`propagate`.</span></span><br><span class="line"><span class="string">            size (tuple, optional): The size :obj:`(N, M)` of the assignment</span></span><br><span class="line"><span class="string">                matrix in case :obj:`edge_index` is a :obj:`LongTensor`.</span></span><br><span class="line"><span class="string">                If set to :obj:`None`, the size will be automatically inferred</span></span><br><span class="line"><span class="string">                and assumed to be quadratic.</span></span><br><span class="line"><span class="string">                This argument is ignored in case :obj:`edge_index` is a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`. (default: :obj:`None`)</span></span><br><span class="line"><span class="string">            **kwargs: Any additional data which is needed to construct and</span></span><br><span class="line"><span class="string">                aggregate messages, and to update node embeddings.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        size = self.__check_input__(edge_index, size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run "fused" message and aggregation (if applicable).</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(edge_index, SparseTensor) <span class="keyword">and</span> self.fuse</span><br><span class="line">                <span class="keyword">and</span> <span class="keyword">not</span> self.__explain__):</span><br><span class="line">            coll_dict = self.__collect__(self.__fused_user_args__, edge_index,</span><br><span class="line">                                         size, kwargs)</span><br><span class="line">            print(<span class="string">"Using self-defined message-passing"</span>)</span><br><span class="line">            msg_aggr_kwargs = self.inspector.distribute(</span><br><span class="line">                <span class="string">'message_and_aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Otherwise, run both functions in separation.</span></span><br><span class="line">        <span class="keyword">elif</span> isinstance(edge_index, Tensor) <span class="keyword">or</span> <span class="keyword">not</span> self.fuse:</span><br><span class="line">            coll_dict = self.__collect__(self.__user_args__, edge_index, size,</span><br><span class="line">                                         kwargs)</span><br><span class="line"></span><br><span class="line">            msg_kwargs = self.inspector.distribute(<span class="string">'message'</span>, coll_dict)</span><br><span class="line">            <span class="comment">#print("Message kwargs: ",msg_kwargs)</span></span><br><span class="line">            out = self.message(**msg_kwargs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># For `GNNExplainer`, we require a separate message and aggregate</span></span><br><span class="line">            <span class="comment"># procedure since this allows us to inject the `edge_mask` into the</span></span><br><span class="line">            <span class="comment"># message passing computation scheme.</span></span><br><span class="line">            <span class="keyword">if</span> self.__explain__:</span><br><span class="line">                edge_mask = self.__edge_mask__.sigmoid()</span><br><span class="line">                <span class="comment"># Some ops add self-loops to `edge_index`. We need to do the</span></span><br><span class="line">                <span class="comment"># same for `edge_mask` (but do not train those).</span></span><br><span class="line">                <span class="keyword">if</span> out.size(self.node_dim) != edge_mask.size(<span class="number">0</span>):</span><br><span class="line">                    loop = edge_mask.new_ones(size[<span class="number">0</span>])</span><br><span class="line">                    edge_mask = torch.cat([edge_mask, loop], dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">assert</span> out.size(self.node_dim) == edge_mask.size(<span class="number">0</span>)</span><br><span class="line">                out = out * edge_mask.view([<span class="number">-1</span>] + [<span class="number">1</span>] * (out.dim() - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            aggr_kwargs = self.inspector.distribute(<span class="string">'aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.aggregate(out, **aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute degree.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, deg_i,deg_j)</span>:</span></span><br><span class="line">        <span class="comment"># Accoding to __collect__ function </span></span><br><span class="line">        <span class="comment"># in https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># i= 1, j=0, edge_index_i = edge_index[1] = target, so </span></span><br><span class="line">        <span class="comment"># deg_i is degree of target node,  and x_i is target node data</span></span><br><span class="line">        <span class="comment"># deg_j is degree of source node and  x_j is source </span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Normalize node features.</span></span><br><span class="line">        print(<span class="string">"--message is called--"</span>)</span><br><span class="line">        print(<span class="string">"x_j: "</span>,x_j.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>, deg_i.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>,deg_j.shape)</span><br><span class="line">        print()</span><br><span class="line">        <span class="comment"># check if degrees of source nodes and degrees of target nodes are equal</span></span><br><span class="line">        print(torch.eq(deg_i, deg_j).all())</span><br><span class="line">        <span class="comment"># compute normalization</span></span><br><span class="line">        deg_i = deg_i.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_j = deg_j.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_i * deg_j</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line">print(<span class="string">"H_nodes: "</span>, h_nodes.shape)</span><br><span class="line">h_nodes</span><br></pre></td></tr></table></figure>

<pre><code>--message is called--
x_j:  torch.Size([13264, 64])
degree:  torch.Size([13264, 1])
degree:  torch.Size([13264, 1])

tensor(False)
H_nodes:  torch.Size([2708, 64])





tensor([[-0.0336, -0.0263, -0.0141,  ..., -0.0157, -0.0207,  0.0233],
        [-0.0204, -0.0698, -0.0737,  ..., -0.0233,  0.0268, -0.0347],
        [-0.0437, -0.0602, -0.0162,  ...,  0.0243,  0.0348, -0.0054],
        ...,
        [-0.0067, -0.0016, -0.0004,  ...,  0.0237, -0.0289,  0.0044],
        [ 0.0061,  0.0198, -0.0076,  ...,  0.0065,  0.0373, -0.0187],
        [ 0.0080,  0.0146, -0.0173,  ..., -0.0250,  0.0205,  0.0163]],
       grad_fn=&lt;ScatterAddBackward&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<br>

<h4 id="5-2-2-在第一个类的基础上，再覆写aggregate函数"><a href="#5-2-2-在第一个类的基础上，再覆写aggregate函数" class="headerlink" title="5.2.2 在第一个类的基础上，再覆写aggregate函数"></a>5.2.2 在第一个类的基础上，再覆写aggregate函数</h4><p>要求不能调用super类的aggregate函数，并且不能直接复制super类的aggregate函数内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor, matmul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.lin2 = torch.nn.Linear(out_channels, out_channels)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute degree.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, deg_i,deg_j)</span>:</span></span><br><span class="line">        <span class="comment"># Accoding to __collect__ function </span></span><br><span class="line">        <span class="comment"># in https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># i= 1, j=0, edge_index_i = edge_index[1] = target, so </span></span><br><span class="line">        <span class="comment"># deg_i is degree of target node,  and x_i is target node data</span></span><br><span class="line">        <span class="comment"># deg_j is degree of source node and  x_j is source </span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Normalize node features.</span></span><br><span class="line">        print(<span class="string">"--message is called--"</span>)</span><br><span class="line">        print(<span class="string">"x_j: "</span>,x_j.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>, deg_i.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>,deg_j.shape)</span><br><span class="line">        print()</span><br><span class="line">        <span class="comment"># check if degrees of source nodes and degrees of target nodes are equal</span></span><br><span class="line">        print(torch.eq(deg_i, deg_j).all())</span><br><span class="line">        <span class="comment"># compute normalization</span></span><br><span class="line">        deg_i = deg_i.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_j = deg_j.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_i * deg_j</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        <span class="comment">#from __collect__() function we know that</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># out['index'] = out['edge_index_i']  -&gt; input index = edge_index[i] = edge_index[1] = index of target node</span></span><br><span class="line">        <span class="comment"># inputs: embedding vectors of source nodes</span></span><br><span class="line">        <span class="comment"># inputs: the outputs from message function, the normalized source node embeding with shape [E, dim of embedding]</span></span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"--aggregate` is called--"</span>)</span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">'ptr: '</span>, ptr)</span><br><span class="line">        print(<span class="string">'dim_size: '</span>,dim_size)</span><br><span class="line">        print(<span class="string">"inputs: "</span>, inputs.shape)</span><br><span class="line">        print(<span class="string">"index: "</span>,index.shape, len(index.unique()))</span><br><span class="line">        print()</span><br><span class="line">        uni_idx = index.unique()</span><br><span class="line">        uni_idx.sort()</span><br><span class="line">        </span><br><span class="line">        res= []</span><br><span class="line">        <span class="comment"># find all unique target node index</span></span><br><span class="line">        <span class="comment"># for each target node, aggregate(sum or mean ) the information from source node to the target node</span></span><br><span class="line">        <span class="comment"># and obtain target node embedding</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> uni_idx:</span><br><span class="line">            <span class="comment"># i is the index of target node</span></span><br><span class="line">            neighbors = inputs[index == i]</span><br><span class="line">            <span class="comment"># aggregate along different vectors of different nodes</span></span><br><span class="line">            <span class="keyword">if</span> self.aggr==<span class="string">"mean"</span>:</span><br><span class="line">                agg_res = neighbors.mean(axis=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                agg_res = neighbors.sum(axis=<span class="number">0</span>)</span><br><span class="line">            res.append(agg_res)</span><br><span class="line">        res = torch.stack(res)</span><br><span class="line">        <span class="keyword">return</span> res </span><br><span class="line">    </span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line">print(<span class="string">"H_nodes: "</span>, h_nodes.shape)</span><br><span class="line">h_nodes</span><br></pre></td></tr></table></figure>

<pre><code>--message is called--
x_j:  torch.Size([13264, 64])
degree:  torch.Size([13264, 1])
degree:  torch.Size([13264, 1])

tensor(False)
--aggregate` is called--
self.aggr: add
ptr:  None
dim_size:  2708
inputs:  torch.Size([13264, 64])
index:  torch.Size([13264]) 2708

H_nodes:  torch.Size([2708, 64])





tensor([[-0.0141,  0.0188,  0.0067,  ..., -0.0314,  0.0296, -0.0301],
        [ 0.0056, -0.0510,  0.0796,  ..., -0.0591,  0.0362,  0.0113],
        [-0.0034,  0.0314,  0.0107,  ..., -0.0433,  0.0407,  0.0185],
        ...,
        [ 0.0280,  0.0239,  0.0307,  ..., -0.0530, -0.0522,  0.0293],
        [-0.0094,  0.0380, -0.0108,  ..., -0.0115,  0.0182, -0.0060],
        [-0.0058, -0.0127, -0.0221,  ..., -0.0027,  0.0008, -0.0052]],
       grad_fn=&lt;StackBackward&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<br>

<h4 id="5-2-3-在第二个类的基础上，再覆写update函数"><a href="#5-2-3-在第二个类的基础上，再覆写update函数" class="headerlink" title="5.2.3 在第二个类的基础上，再覆写update函数"></a>5.2.3 在第二个类的基础上，再覆写update函数</h4><p>要求对节点信息做一层线性变换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor, matmul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.lin2 = torch.nn.Linear(out_channels, out_channels)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(self, edge_index, size=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># I just copy the source copy from PyG website</span></span><br><span class="line">        <span class="string">r"""The initial call to start propagating messages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor` that defines the underlying</span></span><br><span class="line"><span class="string">                graph connectivity/message passing flow.</span></span><br><span class="line"><span class="string">                :obj:`edge_index` holds the indices of a general (sparse)</span></span><br><span class="line"><span class="string">                assignment matrix of shape :obj:`[N, M]`.</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its</span></span><br><span class="line"><span class="string">                shape must be defined as :obj:`[2, num_messages]`, where</span></span><br><span class="line"><span class="string">                messages from nodes in :obj:`edge_index[0]` are sent to</span></span><br><span class="line"><span class="string">                nodes in :obj:`edge_index[1]`</span></span><br><span class="line"><span class="string">                (in case :obj:`flow="source_to_target"`).</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`, its sparse indices</span></span><br><span class="line"><span class="string">                :obj:`(row, col)` should relate to :obj:`row = edge_index[1]`</span></span><br><span class="line"><span class="string">                and :obj:`col = edge_index[0]`.</span></span><br><span class="line"><span class="string">                The major difference between both formats is that we need to</span></span><br><span class="line"><span class="string">                input the *transposed* sparse adjacency matrix into</span></span><br><span class="line"><span class="string">                :func:`propagate`.</span></span><br><span class="line"><span class="string">            size (tuple, optional): The size :obj:`(N, M)` of the assignment</span></span><br><span class="line"><span class="string">                matrix in case :obj:`edge_index` is a :obj:`LongTensor`.</span></span><br><span class="line"><span class="string">                If set to :obj:`None`, the size will be automatically inferred</span></span><br><span class="line"><span class="string">                and assumed to be quadratic.</span></span><br><span class="line"><span class="string">                This argument is ignored in case :obj:`edge_index` is a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`. (default: :obj:`None`)</span></span><br><span class="line"><span class="string">            **kwargs: Any additional data which is needed to construct and</span></span><br><span class="line"><span class="string">                aggregate messages, and to update node embeddings.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        size = self.__check_input__(edge_index, size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run "fused" message and aggregation (if applicable).</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(edge_index, SparseTensor) <span class="keyword">and</span> self.fuse</span><br><span class="line">                <span class="keyword">and</span> <span class="keyword">not</span> self.__explain__):</span><br><span class="line">            coll_dict = self.__collect__(self.__fused_user_args__, edge_index,</span><br><span class="line">                                         size, kwargs)</span><br><span class="line">            print(<span class="string">"Using self-defined message-passing"</span>)</span><br><span class="line">            msg_aggr_kwargs = self.inspector.distribute(</span><br><span class="line">                <span class="string">'message_and_aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Otherwise, run both functions in separation.</span></span><br><span class="line">        <span class="keyword">elif</span> isinstance(edge_index, Tensor) <span class="keyword">or</span> <span class="keyword">not</span> self.fuse:</span><br><span class="line">            coll_dict = self.__collect__(self.__user_args__, edge_index, size,</span><br><span class="line">                                         kwargs)</span><br><span class="line"></span><br><span class="line">            msg_kwargs = self.inspector.distribute(<span class="string">'message'</span>, coll_dict)</span><br><span class="line">            <span class="comment">#print("Message kwargs: ",msg_kwargs)</span></span><br><span class="line">            out = self.message(**msg_kwargs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># For `GNNExplainer`, we require a separate message and aggregate</span></span><br><span class="line">            <span class="comment"># procedure since this allows us to inject the `edge_mask` into the</span></span><br><span class="line">            <span class="comment"># message passing computation scheme.</span></span><br><span class="line">            <span class="keyword">if</span> self.__explain__:</span><br><span class="line">                edge_mask = self.__edge_mask__.sigmoid()</span><br><span class="line">                <span class="comment"># Some ops add self-loops to `edge_index`. We need to do the</span></span><br><span class="line">                <span class="comment"># same for `edge_mask` (but do not train those).</span></span><br><span class="line">                <span class="keyword">if</span> out.size(self.node_dim) != edge_mask.size(<span class="number">0</span>):</span><br><span class="line">                    loop = edge_mask.new_ones(size[<span class="number">0</span>])</span><br><span class="line">                    edge_mask = torch.cat([edge_mask, loop], dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">assert</span> out.size(self.node_dim) == edge_mask.size(<span class="number">0</span>)</span><br><span class="line">                out = out * edge_mask.view([<span class="number">-1</span>] + [<span class="number">1</span>] * (out.dim() - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            aggr_kwargs = self.inspector.distribute(<span class="string">'aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.aggregate(out, **aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute degree.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, deg_i,deg_j)</span>:</span></span><br><span class="line">        <span class="comment"># Accoding to __collect__ function </span></span><br><span class="line">        <span class="comment"># in https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># i= 1, j=0, edge_index_i = edge_index[1] = target, so </span></span><br><span class="line">        <span class="comment"># deg_i is degree of target node,  and x_i is target node data</span></span><br><span class="line">        <span class="comment"># deg_j is degree of source node and  x_j is source </span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Normalize node features.</span></span><br><span class="line">        print(<span class="string">"--message is called--"</span>)</span><br><span class="line">        print(<span class="string">"x_j: "</span>,x_j.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>, deg_i.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>,deg_j.shape)</span><br><span class="line">        print()</span><br><span class="line">        <span class="comment"># check if degrees of source nodes and degrees of target nodes are equal</span></span><br><span class="line">        print(torch.eq(deg_i, deg_j).all())</span><br><span class="line">        <span class="comment"># compute normalization</span></span><br><span class="line">        deg_i = deg_i.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_j = deg_j.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_i * deg_j</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        <span class="comment">#from __collect__() function we know that</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># out['index'] = out['edge_index_i']  -&gt; input index = edge_index[i] = edge_index[1] = index of target node</span></span><br><span class="line">        <span class="comment"># inputs: embedding vectors of source nodes</span></span><br><span class="line">        <span class="comment"># inputs: the outputs from message function, the normalized source node embeding with shape [E, dim of embedding]</span></span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"--aggregate` is called--"</span>)</span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">'ptr: '</span>, ptr)</span><br><span class="line">        print(<span class="string">'dim_size: '</span>,dim_size)</span><br><span class="line">        print(<span class="string">"inputs: "</span>, inputs.shape)</span><br><span class="line">        print(<span class="string">"index: "</span>,index.shape, len(index.unique()))</span><br><span class="line">        print()</span><br><span class="line">        uni_idx = index.unique()</span><br><span class="line">        uni_idx.sort()</span><br><span class="line">        </span><br><span class="line">        res= []</span><br><span class="line">        <span class="comment"># find all unique target node index</span></span><br><span class="line">        <span class="comment"># for each target node, aggregate(sum or mean ) the information from source node to the target node</span></span><br><span class="line">        <span class="comment"># and obtain target node embedding</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> uni_idx:</span><br><span class="line">            <span class="comment"># i is the index of target node</span></span><br><span class="line">            neighbors = inputs[index == i]</span><br><span class="line">            <span class="comment"># aggregate along different vectors of different nodes</span></span><br><span class="line">            <span class="keyword">if</span> self.aggr==<span class="string">"mean"</span>:</span><br><span class="line">                agg_res = neighbors.mean(axis=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                agg_res = neighbors.sum(axis=<span class="number">0</span>)</span><br><span class="line">            res.append(agg_res)</span><br><span class="line">        res = torch.stack(res)</span><br><span class="line">        <span class="keyword">return</span> res </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self,inputs, deg )</span>:</span></span><br><span class="line">        print(<span class="string">"--update func is called--"</span>)</span><br><span class="line">        <span class="keyword">return</span> self.lin2(inputs)</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line">print(<span class="string">"H_nodes: "</span>, h_nodes.shape)</span><br><span class="line">h_nodes</span><br></pre></td></tr></table></figure>

<pre><code>--message is called--
x_j:  torch.Size([13264, 64])
degree:  torch.Size([13264, 1])
degree:  torch.Size([13264, 1])
tensor(False)
--aggregate` is called--
self.aggr: add
ptr:  None
dim_size:  2708
inputs:  torch.Size([13264, 64])
index:  torch.Size([13264]) 2708

--update func is called--
H_nodes:  torch.Size([2708, 64])





tensor([[-0.0139, -0.0065,  0.1316,  ...,  0.0401, -0.1439, -0.0718],
        [-0.0333, -0.0545,  0.1637,  ..., -0.0098, -0.1503, -0.0837],
        [-0.0245, -0.0277,  0.1248,  ...,  0.0264, -0.1423, -0.0829],
        ...,
        [-0.0678, -0.0061,  0.1510,  ...,  0.0332, -0.1420, -0.0876],
        [-0.0289, -0.0100,  0.1211,  ...,  0.0339, -0.1905, -0.0764],
        [-0.0255, -0.0036,  0.1290,  ...,  0.0366, -0.1623, -0.0631]],
       grad_fn=&lt;AddmmBackward&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<br>

<h4 id="5-2-4-在第三个类的基础上，再覆写message-and-aggregate函数"><a href="#5-2-4-在第三个类的基础上，再覆写message-and-aggregate函数" class="headerlink" title="5.2.4 在第三个类的基础上，再覆写message_and_aggregate函数"></a>5.2.4 在第三个类的基础上，再覆写message_and_aggregate函数</h4><p>要求在这一个函数中实现前面message函数和aggregate函数的功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor, matmul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">'add'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.lin2 = torch.nn.Linear(out_channels, out_channels)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(self, edge_index, size=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># I just copy the source copy from PyG website</span></span><br><span class="line">        <span class="string">r"""The initial call to start propagating messages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor` that defines the underlying</span></span><br><span class="line"><span class="string">                graph connectivity/message passing flow.</span></span><br><span class="line"><span class="string">                :obj:`edge_index` holds the indices of a general (sparse)</span></span><br><span class="line"><span class="string">                assignment matrix of shape :obj:`[N, M]`.</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its</span></span><br><span class="line"><span class="string">                shape must be defined as :obj:`[2, num_messages]`, where</span></span><br><span class="line"><span class="string">                messages from nodes in :obj:`edge_index[0]` are sent to</span></span><br><span class="line"><span class="string">                nodes in :obj:`edge_index[1]`</span></span><br><span class="line"><span class="string">                (in case :obj:`flow="source_to_target"`).</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`, its sparse indices</span></span><br><span class="line"><span class="string">                :obj:`(row, col)` should relate to :obj:`row = edge_index[1]`</span></span><br><span class="line"><span class="string">                and :obj:`col = edge_index[0]`.</span></span><br><span class="line"><span class="string">                The major difference between both formats is that we need to</span></span><br><span class="line"><span class="string">                input the *transposed* sparse adjacency matrix into</span></span><br><span class="line"><span class="string">                :func:`propagate`.</span></span><br><span class="line"><span class="string">            size (tuple, optional): The size :obj:`(N, M)` of the assignment</span></span><br><span class="line"><span class="string">                matrix in case :obj:`edge_index` is a :obj:`LongTensor`.</span></span><br><span class="line"><span class="string">                If set to :obj:`None`, the size will be automatically inferred</span></span><br><span class="line"><span class="string">                and assumed to be quadratic.</span></span><br><span class="line"><span class="string">                This argument is ignored in case :obj:`edge_index` is a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`. (default: :obj:`None`)</span></span><br><span class="line"><span class="string">            **kwargs: Any additional data which is needed to construct and</span></span><br><span class="line"><span class="string">                aggregate messages, and to update node embeddings.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        size = self.__check_input__(edge_index, size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run "fused" message and aggregation (if applicable).</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(edge_index, SparseTensor) <span class="keyword">and</span> self.fuse</span><br><span class="line">                <span class="keyword">and</span> <span class="keyword">not</span> self.__explain__):</span><br><span class="line">            coll_dict = self.__collect__(self.__fused_user_args__, edge_index,</span><br><span class="line">                                         size, kwargs)</span><br><span class="line">            <span class="comment">#print("Using self-defined message-passing")</span></span><br><span class="line">            msg_aggr_kwargs = self.inspector.distribute(</span><br><span class="line">                <span class="string">'message_and_aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Otherwise, run both functions in separation.</span></span><br><span class="line">        <span class="keyword">elif</span> isinstance(edge_index, Tensor) <span class="keyword">or</span> <span class="keyword">not</span> self.fuse:</span><br><span class="line">            coll_dict = self.__collect__(self.__user_args__, edge_index, size,</span><br><span class="line">                                         kwargs)</span><br><span class="line"></span><br><span class="line">            msg_kwargs = self.inspector.distribute(<span class="string">'message'</span>, coll_dict)</span><br><span class="line">            <span class="comment">#print("Message kwargs: ",msg_kwargs)</span></span><br><span class="line">            out = self.message(**msg_kwargs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># For `GNNExplainer`, we require a separate message and aggregate</span></span><br><span class="line">            <span class="comment"># procedure since this allows us to inject the `edge_mask` into the</span></span><br><span class="line">            <span class="comment"># message passing computation scheme.</span></span><br><span class="line">            <span class="keyword">if</span> self.__explain__:</span><br><span class="line">                edge_mask = self.__edge_mask__.sigmoid()</span><br><span class="line">                <span class="comment"># Some ops add self-loops to `edge_index`. We need to do the</span></span><br><span class="line">                <span class="comment"># same for `edge_mask` (but do not train those).</span></span><br><span class="line">                <span class="keyword">if</span> out.size(self.node_dim) != edge_mask.size(<span class="number">0</span>):</span><br><span class="line">                    loop = edge_mask.new_ones(size[<span class="number">0</span>])</span><br><span class="line">                    edge_mask = torch.cat([edge_mask, loop], dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">assert</span> out.size(self.node_dim) == edge_mask.size(<span class="number">0</span>)</span><br><span class="line">                out = out * edge_mask.view([<span class="number">-1</span>] + [<span class="number">1</span>] * (out.dim() - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            aggr_kwargs = self.inspector.distribute(<span class="string">'aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.aggregate(out, **aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute degree.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        adjmat = SparseTensor(row=edge_index[<span class="number">0</span>], col=edge_index[<span class="number">1</span>], value=torch.ones(edge_index.shape[<span class="number">1</span>]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.propagate(adjmat, x=x, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, deg_i,deg_j)</span>:</span></span><br><span class="line">        <span class="comment"># Accoding to __collect__ function </span></span><br><span class="line">        <span class="comment"># in https://github.com/rusty1s/pytorch_geometric/blob/master/torch_geometric/nn/conv/message_passing.py</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># i= 1, j=0, edge_index_i = edge_index[1] = target, so </span></span><br><span class="line">        <span class="comment"># deg_i is degree of target node,  and x_i is target node data</span></span><br><span class="line">        <span class="comment"># deg_j is degree of source node and  x_j is source </span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 3: Normalize node features.</span></span><br><span class="line">        print(<span class="string">"--message is called--"</span>)</span><br><span class="line">        print(<span class="string">"x_j: "</span>,x_j.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>, deg_i.shape)</span><br><span class="line">        print(<span class="string">"degree: "</span>,deg_j.shape)</span><br><span class="line">        print()</span><br><span class="line">        <span class="comment"># check if degrees of source nodes and degrees of target nodes are equal</span></span><br><span class="line">        print(torch.eq(deg_i, deg_j).all())</span><br><span class="line">        <span class="comment"># compute normalization</span></span><br><span class="line">        deg_i = deg_i.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_j = deg_j.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_i * deg_j</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        <span class="comment">#from __collect__() function we know that</span></span><br><span class="line">        <span class="comment"># when flow = source_to_target</span></span><br><span class="line">        <span class="comment"># out['index'] = out['edge_index_i']  -&gt; input index = edge_index[i] = edge_index[1] = index of target node</span></span><br><span class="line">        <span class="comment"># inputs: embedding vectors of source nodes</span></span><br><span class="line">        <span class="comment"># inputs: the outputs from message function, the normalized source node embeding with shape [E, dim of embedding]</span></span><br><span class="line">        </span><br><span class="line">        print(<span class="string">"--aggregate` is called--"</span>)</span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">'ptr: '</span>, ptr)</span><br><span class="line">        print(<span class="string">'dim_size: '</span>,dim_size)</span><br><span class="line">        print(<span class="string">"inputs: "</span>, inputs.shape)</span><br><span class="line">        print(<span class="string">"index: "</span>,index.shape, len(index.unique()))</span><br><span class="line">        print()</span><br><span class="line">        uni_idx = index.unique()</span><br><span class="line">        uni_idx.sort()</span><br><span class="line">        </span><br><span class="line">        res= []</span><br><span class="line">        <span class="comment"># find all unique target node index</span></span><br><span class="line">        <span class="comment"># for each target node, aggregate(sum or mean ) the information from source node to the target node</span></span><br><span class="line">        <span class="comment"># and obtain target node embedding</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> uni_idx:</span><br><span class="line">            <span class="comment"># i is the index of target node</span></span><br><span class="line">            neighbors = inputs[index == i]</span><br><span class="line">            <span class="comment"># aggregate along different vectors of different nodes</span></span><br><span class="line">            <span class="keyword">if</span> self.aggr==<span class="string">"mean"</span>:</span><br><span class="line">                agg_res = neighbors.mean(axis=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                agg_res = neighbors.sum(axis=<span class="number">0</span>)</span><br><span class="line">            res.append(agg_res)</span><br><span class="line">        res = torch.stack(res)</span><br><span class="line">        <span class="keyword">return</span> res </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message_and_aggregate</span><span class="params">(self, adj_t, x_j, index,deg_i, deg_j)</span>:</span></span><br><span class="line">        <span class="comment"># note: </span></span><br><span class="line">        <span class="comment"># adj_t: adjacency matrix</span></span><br><span class="line">        <span class="comment"># norm: normalization coefficient 1/sqrt(deg_i)*sqrt(deg_j)</span></span><br><span class="line">        <span class="comment"># number of '1' in adj_t = length of norm</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## Print something to debug</span></span><br><span class="line">        <span class="comment">#print('`message_and_aggregate` is called')</span></span><br><span class="line">        <span class="comment">#print("adj_t: ",adj_t)</span></span><br><span class="line">        <span class="comment">#print("deg:", deg)</span></span><br><span class="line">        print(<span class="string">"--message_and_aggregate is called --"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step3:  compute normalization</span></span><br><span class="line">        deg_i = deg_i.pow(<span class="number">-0.5</span>)</span><br><span class="line">        deg_j = deg_j.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_i * deg_j</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step4: compute normalized message</span></span><br><span class="line">        inputs = norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step5: aggregate function sum</span></span><br><span class="line">        uni_idx = index.unique()</span><br><span class="line">        uni_idx.sort()</span><br><span class="line">        </span><br><span class="line">        res= []</span><br><span class="line">        <span class="comment"># find all unique target node index</span></span><br><span class="line">        <span class="comment"># for each target node, aggregate(sum or mean ) the information from source node to the target node</span></span><br><span class="line">        <span class="comment"># and obtain target node embedding</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> uni_idx:</span><br><span class="line">            <span class="comment"># i is the index of target node</span></span><br><span class="line">            neighbors = inputs[index == i]</span><br><span class="line">            <span class="comment"># aggregate along different vectors of different nodes</span></span><br><span class="line">            <span class="keyword">if</span> self.aggr==<span class="string">"mean"</span>:</span><br><span class="line">                agg_res = neighbors.mean(axis=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                agg_res = neighbors.sum(axis=<span class="number">0</span>)</span><br><span class="line">            res.append(agg_res)</span><br><span class="line">        res = torch.stack(res)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self,inputs, deg )</span>:</span></span><br><span class="line">        print(<span class="string">"--update func is called--"</span>)</span><br><span class="line">        <span class="keyword">return</span> self.lin2(inputs)</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = GCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br><span class="line">print(<span class="string">"H_nodes: "</span>, h_nodes.shape)</span><br><span class="line">h_nodes</span><br></pre></td></tr></table></figure>

<pre><code>--message_and_aggregate is called --
--update func is called--
H_nodes:  torch.Size([2708, 64])





tensor([[-0.0301, -0.0607, -0.0843,  ..., -0.0092,  0.0735,  0.1196],
        [-0.0287, -0.0805, -0.0924,  ..., -0.0665,  0.0596,  0.0680],
        [-0.0236, -0.0952, -0.1220,  ..., -0.0735,  0.0296,  0.0909],
        ...,
        [-0.0257, -0.0769, -0.0840,  ..., -0.0068,  0.0807,  0.1330],
        [-0.0402, -0.0765, -0.1098,  ..., -0.0396,  0.0407,  0.1058],
        [-0.0421, -0.0787, -0.1024,  ..., -0.0455,  0.0361,  0.1054]],
       grad_fn=&lt;AddmmBackward&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<br>

<h3 id="5-3-设计自定义一个GCN-layer"><a href="#5-3-设计自定义一个GCN-layer" class="headerlink" title="5.3 设计自定义一个GCN layer"></a>5.3 <strong>设计自定义一个GCN layer</strong></h3><p>这里我自定义的GCN layer公式如下：<br>$$<br>\mathbf{x}_ i^{(k)} = \sigma(\frac{1}{|\mathcal{N}(i)|+1} \times \sum_{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot ( \mathbf{\Theta} \cdot \mathbf{x}_ j^{(k-1)} ) ) +  \mathbf{\Theta}  \cdot \mathbf{x}_ i^{(k-1)} ,<br>$$</p>
<p>这里一些函数定义如下：</p>
<ul>
<li>$\phi(..)$: message函数和之前的GCN一样都是linear projection之后用degree进行normalization</li>
<li>$\square(..)$ : aggregate 函数 用来mean</li>
<li>$\gamma(..)$: update 函数是先用了ReLu activation函数, 在加上shortcut把之前投映之后的输入加上来，模拟了resnet的结构</li>
<li>这里只用了 message_and_aggregate 函数，所以没有实现message， aggregate的单独的函数</li>
<li>propagate 函数是直接从官方文档copy过来，方便理解GNN的propagate的流程的。 从中可以看到，如果输入到propagate的tensor是SparseTensor, 那么会直接调用message_and_aggregate函数，而不是单独调用两个函数，所以只要实现这个合并的函数就行了</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, Tensor</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"><span class="keyword">from</span> torch_sparse <span class="keyword">import</span> SparseTensor, matmul</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyGCNConv</span><span class="params">(MessagePassing)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels)</span>:</span></span><br><span class="line">        super(MyGCNConv, self).__init__(aggr=<span class="string">'mean'</span>, flow=<span class="string">'source_to_target'</span>)</span><br><span class="line">        <span class="comment"># "Add" aggregation (Step 5).</span></span><br><span class="line">        <span class="comment"># flow='source_to_target' 表示消息从源节点传播到目标节点</span></span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line">        self.relu = torch.nn.ReLU()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(self, edge_index, size=None, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># I just copy the source copy from PyG website</span></span><br><span class="line">        <span class="string">r"""The initial call to start propagating messages.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor` that defines the underlying</span></span><br><span class="line"><span class="string">                graph connectivity/message passing flow.</span></span><br><span class="line"><span class="string">                :obj:`edge_index` holds the indices of a general (sparse)</span></span><br><span class="line"><span class="string">                assignment matrix of shape :obj:`[N, M]`.</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its</span></span><br><span class="line"><span class="string">                shape must be defined as :obj:`[2, num_messages]`, where</span></span><br><span class="line"><span class="string">                messages from nodes in :obj:`edge_index[0]` are sent to</span></span><br><span class="line"><span class="string">                nodes in :obj:`edge_index[1]`</span></span><br><span class="line"><span class="string">                (in case :obj:`flow="source_to_target"`).</span></span><br><span class="line"><span class="string">                If :obj:`edge_index` is of type</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`, its sparse indices</span></span><br><span class="line"><span class="string">                :obj:`(row, col)` should relate to :obj:`row = edge_index[1]`</span></span><br><span class="line"><span class="string">                and :obj:`col = edge_index[0]`.</span></span><br><span class="line"><span class="string">                The major difference between both formats is that we need to</span></span><br><span class="line"><span class="string">                input the *transposed* sparse adjacency matrix into</span></span><br><span class="line"><span class="string">                :func:`propagate`.</span></span><br><span class="line"><span class="string">            size (tuple, optional): The size :obj:`(N, M)` of the assignment</span></span><br><span class="line"><span class="string">                matrix in case :obj:`edge_index` is a :obj:`LongTensor`.</span></span><br><span class="line"><span class="string">                If set to :obj:`None`, the size will be automatically inferred</span></span><br><span class="line"><span class="string">                and assumed to be quadratic.</span></span><br><span class="line"><span class="string">                This argument is ignored in case :obj:`edge_index` is a</span></span><br><span class="line"><span class="string">                :obj:`torch_sparse.SparseTensor`. (default: :obj:`None`)</span></span><br><span class="line"><span class="string">            **kwargs: Any additional data which is needed to construct and</span></span><br><span class="line"><span class="string">                aggregate messages, and to update node embeddings.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        size = self.__check_input__(edge_index, size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Run "fused" message and aggregation (if applicable).</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(edge_index, SparseTensor) <span class="keyword">and</span> self.fuse</span><br><span class="line">                <span class="keyword">and</span> <span class="keyword">not</span> self.__explain__):</span><br><span class="line">            coll_dict = self.__collect__(self.__fused_user_args__, edge_index,</span><br><span class="line">                                         size, kwargs)</span><br><span class="line">            print(<span class="string">"Using self-defined message-passing"</span>)</span><br><span class="line">            msg_aggr_kwargs = self.inspector.distribute(</span><br><span class="line">                <span class="string">'message_and_aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.message_and_aggregate(edge_index, **msg_aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Otherwise, run both functions in separation.</span></span><br><span class="line">        <span class="keyword">elif</span> isinstance(edge_index, Tensor) <span class="keyword">or</span> <span class="keyword">not</span> self.fuse:</span><br><span class="line">            coll_dict = self.__collect__(self.__user_args__, edge_index, size,</span><br><span class="line">                                         kwargs)</span><br><span class="line"></span><br><span class="line">            msg_kwargs = self.inspector.distribute(<span class="string">'message'</span>, coll_dict)</span><br><span class="line">            out = self.message(**msg_kwargs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># For `GNNExplainer`, we require a separate message and aggregate</span></span><br><span class="line">            <span class="comment"># procedure since this allows us to inject the `edge_mask` into the</span></span><br><span class="line">            <span class="comment"># message passing computation scheme.</span></span><br><span class="line">            <span class="keyword">if</span> self.__explain__:</span><br><span class="line">                edge_mask = self.__edge_mask__.sigmoid()</span><br><span class="line">                <span class="comment"># Some ops add self-loops to `edge_index`. We need to do the</span></span><br><span class="line">                <span class="comment"># same for `edge_mask` (but do not train those).</span></span><br><span class="line">                <span class="keyword">if</span> out.size(self.node_dim) != edge_mask.size(<span class="number">0</span>):</span><br><span class="line">                    loop = edge_mask.new_ones(size[<span class="number">0</span>])</span><br><span class="line">                    edge_mask = torch.cat([edge_mask, loop], dim=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">assert</span> out.size(self.node_dim) == edge_mask.size(<span class="number">0</span>)</span><br><span class="line">                out = out * edge_mask.view([<span class="number">-1</span>] + [<span class="number">1</span>] * (out.dim() - <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">            aggr_kwargs = self.inspector.distribute(<span class="string">'aggregate'</span>, coll_dict)</span><br><span class="line">            out = self.aggregate(out, **aggr_kwargs)</span><br><span class="line"></span><br><span class="line">            update_kwargs = self.inspector.distribute(<span class="string">'update'</span>, coll_dict)</span><br><span class="line">            <span class="keyword">return</span> self.update(out, **update_kwargs)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, edge_index)</span>:</span></span><br><span class="line">        <span class="comment"># x has shape [N, in_channels]</span></span><br><span class="line">        <span class="comment"># edge_index has shape [2, E]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 1: Add self-loops to the adjacency matrix.</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 2: Linearly transform node feature matrix.</span></span><br><span class="line">        x = self.lin(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Step 3: Compute normalization.</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        <span class="comment"># note: norm is in shape of (number of edge, )</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line">        print(<span class="string">"Get degree Shape: "</span>, edge_index.shape)</span><br><span class="line">        print(<span class="string">"Norm Shape: "</span>,norm.shape)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Step 4-5: Start propagating messages.</span></span><br><span class="line">        <span class="comment"># Convert edge index to a sparse adjacency matrix representation, with row = from nodes, col = to nodes. </span></span><br><span class="line">        <span class="comment"># When value =  1 in adjacency matrix, it indicates two nodes are adjacent.</span></span><br><span class="line">        <span class="comment"># adjmat = SparseTensor(row=edge_index[0], col=edge_index[1], value=torch.ones(edge_index.shape[1]))</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这里 adjacency matrix 的值从1 变成 normalization 的值，方便乘法计算</span></span><br><span class="line">        adjmat = SparseTensor(row=edge_index[<span class="number">0</span>], col=edge_index[<span class="number">1</span>], value=norm)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 此处传的不再是edge_idex，而是SparseTensor类型的Adjancency Matrix</span></span><br><span class="line">        <span class="keyword">return</span> self.propagate(adjmat, x=x, norm=norm, deg=deg.view((<span class="number">-1</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span><span class="params">(self, x_j, norm, deg_i)</span>:</span></span><br><span class="line">        <span class="comment"># x_j has shape [E, out_channels]</span></span><br><span class="line">        <span class="comment"># deg_i has shape [E, 1]</span></span><br><span class="line">        <span class="comment"># Step 4: Normalize node features.</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j * deg_i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">aggregate</span><span class="params">(self, inputs, index, ptr, dim_size)</span>:</span></span><br><span class="line">        print(<span class="string">'self.aggr:'</span>, self.aggr)</span><br><span class="line">        print(<span class="string">"`aggregate` is called"</span>)</span><br><span class="line">        <span class="keyword">return</span> super().aggregate(inputs, index, ptr=ptr, dim_size=dim_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message_and_aggregate</span><span class="params">(self, adj_t, x, norm,deg)</span>:</span></span><br><span class="line">        <span class="comment"># note: </span></span><br><span class="line">        <span class="comment"># adj_t: adjacency matrix</span></span><br><span class="line">        <span class="comment"># norm: normalization coefficient 1/sqrt(deg_i)*sqrt(deg_j)</span></span><br><span class="line">        <span class="comment"># number of '1' in adj_t = length of norm</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">## Print something to debug</span></span><br><span class="line">        <span class="comment">#print('`message_and_aggregate` is called')</span></span><br><span class="line">        <span class="comment">#print("adj_t: ",adj_t)</span></span><br><span class="line">        <span class="comment">#print("deg:", deg)</span></span><br><span class="line">        </span><br><span class="line">        adj_t = adj_t.to_dense()</span><br><span class="line">        N = len(adj_t)</span><br><span class="line">        out = []</span><br><span class="line">        x0 = x[:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">            <span class="comment"># 计算每个 xi 的neighbor传过来的信息的平均值</span></span><br><span class="line">            x_sum = torch.matmul(x.T,adj_t[i])</span><br><span class="line">            x_avg = x_sum/deg[i]</span><br><span class="line">            out.append(x_avg)</span><br><span class="line">        out = torch.stack(out)</span><br><span class="line">        <span class="keyword">return</span> [out, x0]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">(self, inputs, deg)</span>:</span></span><br><span class="line">        print(<span class="string">"Update result"</span>)</span><br><span class="line">        print(<span class="string">"Degree"</span>,deg)</span><br><span class="line">        <span class="comment"># resnet的结构</span></span><br><span class="line">        x0 = inputs[<span class="number">1</span>]</span><br><span class="line">        output = self.relu(inputs[<span class="number">0</span>]) + x0</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">'dataset/Cora'</span>, name=<span class="string">'Cora'</span>)</span><br><span class="line">data = dataset[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">net = MyGCNConv(data.num_features, <span class="number">64</span>)</span><br><span class="line">h_nodes = net(data.x, data.edge_index)</span><br></pre></td></tr></table></figure>

<pre><code>Get degree Shape:  torch.Size([2, 13264])
Norm Shape:  torch.Size([13264])
Using self-defined message-passing
Update result
Degree tensor([[4.],
        [4.],
        [6.],
        ...,
        [2.],
        [5.],
        [5.]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h_nodes</span><br></pre></td></tr></table></figure>




<pre><code>tensor([[-2.4017e-02,  4.7570e-02,  1.1954e-02,  ...,  1.3043e-02,
          2.0967e-02, -8.4416e-02],
        [-8.5681e-02,  1.2029e-01,  1.0756e-01,  ...,  5.4046e-02,
         -8.9611e-02, -1.9092e-01],
        [ 6.2691e-02, -2.7604e-02, -6.0106e-02,  ..., -3.0790e-05,
          7.8295e-03, -7.2708e-02],
        ...,
        [ 2.0562e-02,  6.4994e-02,  1.0240e-01,  ..., -3.2108e-03,
          6.4759e-02,  1.3680e-02],
        [-1.9234e-02, -2.0179e-02,  3.0165e-02,  ..., -1.4412e-01,
         -4.2793e-02, -5.4195e-02],
        [-2.6318e-02, -2.6606e-02,  9.8404e-02,  ..., -5.1031e-02,
         -2.9973e-02,  1.8722e-02]], grad_fn=&lt;AddBackward0&gt;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Datawhale 参考资料: <a href="https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/4-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md">https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/4-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md</a></p>
<p>[2] PyG官方文档：<a href="https://pytorch-geometric.readthedocs.io/en/latest/index.html">https://pytorch-geometric.readthedocs.io/en/latest/index.html</a><br>[3] paper: <a href="https://arxiv.org/pdf/2007.02133.pdf">https://arxiv.org/pdf/2007.02133.pdf</a><br>[4] paper: <a href="https://arxiv.org/pdf/1609.02907.pdf">https://arxiv.org/pdf/1609.02907.pdf</a><br>[5] Deep Learning on Graph: <a href="https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/4-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md">https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/4-%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.md</a><br>[6] PyG MessagePassing 函数解释: <a href="https://blog.csdn.net/qq_41987033/article/details/103377561">https://blog.csdn.net/qq_41987033/article/details/103377561</a></p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/GNN/">GNN</a><a class="link-muted mr-2" rel="tag" href="/tags/Graph/">Graph</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://ppoffice.github.io/hexo-theme-icarus-categorites-Plugins/Share/" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/06/23/GNN-3-NodeEmbedding/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">GNN-3-NodeEmbedding</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/06/16/GNN-1-Basic/"><span class="level-item">GNN-1-Basic</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "kvXCKmDNxnA2486N29e5cP7i-MdYXbMMI",
            appKey: "0Lv5b0SqotzkGHQvD64u4AKo",
            
            avatar: "mm",
            
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "en",
            
            highlight: true,
            
            
            
            
            
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://github.com/wenkangwei" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Data-Collection/"><span class="level-start"><span class="level-item">Data Collection</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Data-Structure/"><span class="level-start"><span class="level-item">Data Structure</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Data-Structure/Sorting/"><span class="level-start"><span class="level-item">Sorting</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Icarus/"><span class="level-start"><span class="level-item">Icarus</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Icarus/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Icarus/Hexo/Website/"><span class="level-start"><span class="level-item">Website</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Machine-Learning/Accuracy-Improvement/"><span class="level-start"><span class="level-item">Accuracy Improvement</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/NLP/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Parallel-Computing/"><span class="level-start"><span class="level-item">Parallel Computing</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/PySpark/"><span class="level-start"><span class="level-item">PySpark</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Recommendation-System/"><span class="level-start"><span class="level-item">Recommendation System</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Report/"><span class="level-start"><span class="level-item">Report</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Searching/"><span class="level-start"><span class="level-item">Searching</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Searching/Data-Strucure/"><span class="level-start"><span class="level-item">Data Strucure</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Statistic/"><span class="level-start"><span class="level-item">Statistic</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Website/"><span class="level-start"><span class="level-item">Website</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Website/ICarus/"><span class="level-start"><span class="level-item">ICarus</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Website/ICarus/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Amdahl-s-Law/"><span class="tag">Amdahl&#039;s Law</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Backpropagation/"><span class="tag">Backpropagation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bagging/"><span class="tag">Bagging</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BeautifulSoup/"><span class="tag">BeautifulSoup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Tree/"><span class="tag">Binary Tree</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Blending/"><span class="tag">Blending</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting/"><span class="tag">Boosting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Boosting-Machine/"><span class="tag">Boosting Machine</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BuckSort/"><span class="tag">BuckSort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Collaborative-Filtering/"><span class="tag">Collaborative Filtering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Confusion-Metric/"><span class="tag">Confusion Metric</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Convolution-Neural-Network/"><span class="tag">Convolution Neural Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Validation/"><span class="tag">Cross Validation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/D3-js/"><span class="tag">D3.js</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DCN/"><span class="tag">DCN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DIN/"><span class="tag">DIN</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Analysis/"><span class="tag">Data Analysis</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Mining/"><span class="tag">Data Mining</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Datawhale-Team-Learning/"><span class="tag">Datawhale Team Learning</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepFM/"><span class="tag">DeepFM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dropout/"><span class="tag">Dropout</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EGES/"><span class="tag">EGES</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ensemble-Learning/"><span class="tag">Ensemble Learning</span><span class="tag is-grey-lightest">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FFM-Model/"><span class="tag">FFM Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GATE/"><span class="tag">GATE</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GNN/"><span class="tag">GNN</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag is-grey-lightest">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph-Embedding/"><span class="tag">Graph Embedding</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Holdout/"><span class="tag">Holdout</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hypothesis-Test/"><span class="tag">Hypothesis Test</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Independence-Test/"><span class="tag">Independence Test</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Installation/"><span class="tag">Installation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/K-Mean-Clustering/"><span class="tag">K-Mean Clustering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KMean-Clustering/"><span class="tag">KMean Clustering</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LGBM/"><span class="tag">LGBM</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Markdown/"><span class="tag">Markdown</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Evaluation/"><span class="tag">Model Evaluation</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Model-Selection/"><span class="tag">Model Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Natural-Language-Representations/"><span class="tag">Natural Language Representations</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Nature-Language-Processing/"><span class="tag">Nature Language Processing</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Negative-Sampling/"><span class="tag">Negative Sampling</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NeuralFM/"><span class="tag">NeuralFM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/P-value/"><span class="tag">P-value</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Parallel-Computing/"><span class="tag">Parallel Computing</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Parallel-Speedup/"><span class="tag">Parallel Speedup</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PySpark/"><span class="tag">PySpark</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROC-curve/"><span class="tag">ROC curve</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Recommendation-System/"><span class="tag">Recommendation System</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regular-Expression/"><span class="tag">Regular Expression</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sorting/"><span class="tag">Sorting</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stacking/"><span class="tag">Stacking</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Swing/"><span class="tag">Swing</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Traversal/"><span class="tag">Traversal</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tutorial/"><span class="tag">Tutorial</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unsupervised-Learning/"><span class="tag">Unsupervised Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Variable-Selection/"><span class="tag">Variable Selection</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSDM/"><span class="tag">WSDM</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Web-Scrapping/"><span class="tag">Web Scrapping</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-and-Deep/"><span class="tag">Wide and Deep</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-and-Deep-Model/"><span class="tag">Wide and Deep Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Wide-Deep-Model/"><span class="tag">Wide&amp;Deep Model</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-vector/"><span class="tag">Word vector</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/binary-search/"><span class="tag">binary search</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/bubble-sort/"><span class="tag">bubble sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/commands/"><span class="tag">commands</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/insertion-sort/"><span class="tag">insertion sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/merge-sort/"><span class="tag">merge sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/non-parametric-learning/"><span class="tag">non-parametric learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/quick-sort/"><span class="tag">quick sort</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/review/"><span class="tag">review</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/statistic-analytics-tool/"><span class="tag">statistic analytics tool</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-09-13T03:23:51.000Z">2021-09-12</time></p><p class="title is-6"><a class="link-muted" href="/2021/09/13/Recommendation-System-9-Swing-1/">Recommendation-System-9-Swing</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-09-13T03:08:12.000Z">2021-09-12</time></p><p class="title is-6"><a class="link-muted" href="/2021/09/13/Recommendation-System-9-Swing/">Recommendation-System-9-Swing</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-08-12T13:59:35.000Z">2021-08-12</time></p><p class="title is-6"><a class="link-muted" href="/2021/08/12/ensemble-learning-XGBoost/">XGBoost + LGBM</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-08-02T22:04:17.000Z">2021-08-02</time></p><p class="title is-6"><a class="link-muted" href="/2021/08/03/Recommendation-System-GraphEmbedding/">Recommendation-System-EGES</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-07-30T17:07:01.000Z">2021-07-30</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/31/Recommendation-System-7-FFM/">Recommendation-System-7-FFM</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Recommendation-System/">Recommendation System</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/09/"><span class="level-start"><span class="level-item">September 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/08/"><span class="level-start"><span class="level-item">August 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/07/"><span class="level-start"><span class="level-item">July 2021</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/06/"><span class="level-start"><span class="level-item">June 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/05/"><span class="level-start"><span class="level-item">May 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/02/"><span class="level-start"><span class="level-item">February 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/12/"><span class="level-start"><span class="level-item">December 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/images/avatar.jpg" alt="Wenkang Wei"></figure><p class="title is-size-4 is-block line-height-inherit">Wenkang Wei</p><p class="is-size-6 is-block">computer engineering| machine learning</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Clemson,SC</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">57</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">25</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">76</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wenkangwei" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wenkangwei"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/wenkang-wei-588811167"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a></div></div></div><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#GNN-2-Message-Passing-消息传递神经网络"><span class="mr-2">1</span><span>GNN-2-Message Passing 消息传递神经网络</span></a><ul class="menu-list"><li><a class="is-flex" href="#1-Introduction"><span class="mr-2">1.1</span><span>1. Introduction</span></a></li><li><a class="is-flex" href="#2-How-Message-Passing-works"><span class="mr-2">1.2</span><span>2.How Message Passing works</span></a></li><li><a class="is-flex" href="#3-MessagePassing-Class-in-PyTorch-Geometric"><span class="mr-2">1.3</span><span>3. MessagePassing Class in PyTorch Geometric</span></a><ul class="menu-list"><li><a class="is-flex" href="#3-1-MessagePassing-的Base-Class-函数"><span class="mr-2">1.3.1</span><span>3.1 MessagePassing 的Base Class 函数</span></a></li><li><a class="is-flex" href="#3-2-5-update-函数的输入"><span class="mr-2">1.3.2</span><span>3.2.5 update 函数的输入</span></a></li></ul></li><li><a class="is-flex" href="#4-Coding-Practice"><span class="mr-2">1.4</span><span>4. Coding Practice</span></a><ul class="menu-list"><li><a class="is-flex" href="#4-1-基于-Message-Passing的泛式-框架-搭建Graph-Convolution-Network-GCN"><span class="mr-2">1.4.1</span><span>4.1 基于 Message Passing的泛式(框架)搭建Graph Convolution Network (GCN)</span></a></li><li><a class="is-flex" href="#4-2-Overwrite-methods-messsage-aggregate-update"><span class="mr-2">1.4.2</span><span>4.2 Overwrite methods: messsage, aggregate, update</span></a></li></ul></li><li><a class="is-flex" href="#5-Assignment"><span class="mr-2">1.5</span><span>5. Assignment</span></a><ul class="menu-list"><li><a class="is-flex" href="#5-1-Message-Passing-机制总结"><span class="mr-2">1.5.1</span><span>5.1 Message Passing 机制总结</span></a></li><li><a class="is-flex" href="#5-2-4-在第三个类的基础上，再覆写message-and-aggregate函数"><span class="mr-2">1.5.2</span><span>5.2.4 在第三个类的基础上，再覆写message_and_aggregate函数</span></a></li><li><a class="is-flex" href="#5-3-设计自定义一个GCN-layer"><span class="mr-2">1.5.3</span><span>5.3 设计自定义一个GCN layer</span></a></li></ul></li></ul></li><li><a class="is-flex" href="#Reference"><span class="mr-2">2</span><span>Reference</span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/icon.png" alt="Wenkang&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2021 Wenkang Wei</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://github.com/wenkangwei/wenkangwei.github.io`',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://s9.cnzz.com/z_stat.php?id=1280124407&amp;web_id=1280124407" async></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>